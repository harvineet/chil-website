{
  "2020": {
    "highlights": "ACM CHIL 2020 was held virtually on July 23rd and 24th. It featured 23 research talks from accepted papers, 23 workshop spotlights, and 15 participants in the doctoral symposium.\n\n### Keynotes\n\n- Yoshua Bengio - <a href=\"https://slideslive.com/38931907/machine-learning-challenges-in-the-fight-for-social-good-the-covid19-case\" target=\"_blank\" rel=\"noopener\">_Machine Learning Challenges in the Fight for Social Good - the Covid-19 Case_</a>\n- Elaine Nsoesie - <a href=\"https://slideslive.com/38931908/digital-platforms-public-health-in-africa\" target=\"_blank\" rel=\"noopener\">_Digital Platforms & Public Health in Africa_</a>\n- Sherri Rose - <a href=\"https://slideslive.com/38931910/machine-learning-in-health-care-too-important-to-be-a-toy-example\" target=\"_blank\" rel=\"noopener\">_Machine Learning in Health Care: Too Important to Be a Toy Example_</a>\n- Ruslan Salakhutdinov - <a href=\"https://slideslive.com/38931911/incorporating-domain-knowledge-into-deep-learning-models\" target=\"_blank\" rel=\"noopener\">_Incorporating Domain Knowledge into Deep Learning Models_</a>\n- Nigam Shah - <a href=\"https://slideslive.com/38931909/a-framework-for-shaping-the-future-of-ai-in-healthcare \" target=\"_blank\" rel=\"noopener\">_A framework for shaping the future of AI in healthcare_</a>\n\n### Tutorials\n\n- A Tour of Survival Analysis, from Classical to Modern - George H. Chen, Jeremy C. Weiss\n- Population and public health: challenges and opportunities - Vishwali Mhasawade, Yuan Zhao, Rumi Chunara\n- Public Health Datasets for Deep Learning: Challenges and Opportunities - Ziad Obermeyer, Katy Haynes, Amy Pitelka, Josh Risley, Katie Lin\n- State of the Art Deep Learning in Medical Imaging - Joseph Paul Cohen\n- Analyzing critical care data, from speculation to publication, starring MIMIC-IV (part 1) - Alistair Johnson\n\n\n### Papers\n\nProceedings from the 2020 ACM CHIL Conference are available at the ACM Digital Library: <a href=\"https://dl.acm.org/doi/proceedings/10.1145/3368555\" target=\"_blank\" rel=\"noopener\">https://dl.acm.org/doi/proceedings/10.1145/3368555</a>\n\n### Governing Board\n\n###### **General Chair**\n- Dr. Marzyeh Ghassemi of the University of Toronto and the Vector Institute\n###### **Logistics Chair**\n- Tasmie Sarker of the University of Toronto and the Vector Institute\n###### **Program Chair**\n- Dr. Tristan Naumann of Microsoft Research Seattle\n- Dr. Danielle Belgrave of Microsoft Research Cambridge, UK\n- Dr. Adrian Dalca of MIT and Harvard Medical School\n###### **Proceedings Chair**\n- Dr. Brett Beaulieu-Jones of Harvard Medical School\n- Sam Finlayson of Harvard University and MIT\n- Emily Alsentzer of Harvard University and MIT\n###### **Communications Chair**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge, UK\n- Dr. Shalmali Joshi of the Vector Institute\n- Bret Nestor of the University of Toronto and the Vector Institute\n###### **Finance Chair**\n- Dr. Joyce Ho of Emory University\n- Dr. Laura Rosella of the University of Toronto\n###### **Tutorial Chair**\n- Ahmed Nasir of Trillium Health Partners\n- Dr. Andrew Beam of Harvard University\n- Irene Chen of MIT\n###### **Consortium Chair**\n- Dr. Leo Celi of MIT\n- Matthew McDermott of MIT\n###### **Virtual Chair**\n- Dr. Tom Pollard of MIT\n- Dr. Alistair Johnson of MIT\n\n### Executive Committee\n- Dr. Marzyeh Ghassemi of University of Toronto, Vector Institute\n- Dr. Tristan Naumann of Microsoft Research Seattle\n- Dr. Joyce Ho of Emory University\n- Dr. Leo Celi of MIT\n- Dr. Shalmali Joshi of the Vector Institute\n- Dr. Andrew Beam of Harvard University\n- Dr. Ziad Obermeyer of University of California, Berkeley\n- Dr. Oluwasanmi Koyejo of University of Illinois at Urbana-Champaign\n- Dr. Avi Goldfarb of Rotman School of Management, University of Toronto\n- Dr. Laura Rosella of Dalla Lana School of Public Health, University of Toronto\n- Dr. Adrian Dalca of MIT and Harvard Medical School\n- Dr. Rajesh Ranganath of NYU\n- Irene Chen of MIT\n- Matthew McDermott of MIT\n- Dr. Katherine Heller at Duke University\n- Dr. Uri Shalit of Technion\n- Dr. Stephanie Hyland of Microsoft Research Cambridge, UK\n- Dr. Danielle Belgrave of Microsoft Research Cambridge, UK\n- Dr. Shakir Mohamed of DeepMind\n- Dr. Alistair Johnson of MIT\n- Dr. Tom Pollard of MIT\n- Dr. Alan Karthikesalingam of Google Health UK\n\n### Steering Committee\n- Dr. Nigam Shah of Stanford University\n- Dr. Stephen Friend of Oxford University\n- Dr. Samantha Kleinberg of Stevens Institute of Technology\n- Dr. Anna Goldenberg of The Hospital for Sick Children Research Institute\n- Dr. Lucila Ohno-Machado of University of California, San Diego\n- Dr. Noemie Elhadad of Columbia University\n\n### Sponsors\nWe thank the Association for Computing Machinery (ACM) for sponsoring CHIL 2020, as well as the following organizations for supporting the event:\n\n- Google\n- Health[at]Scale\n- Layer6\n- Apple\n- CIFAR\n- Imagia\n- Microsoft\n- Sun Life Financial\n- Creative Destruction Lab\n- Vector Institute\n", 
    "proceedings": [
      {
        "UID": "20P01", 
        "abstract": "A key impediment to reinforcement learning (RL) in real applications with limited, batch data is in defining a reward function that reflects what we implicitly know about reasonable behaviour for a task and allows for robust off-policy evaluation. In this work, we develop a method to identify an admissible set of reward functions for policies that (a) do not deviate too far in performance from prior behaviour, and (b) can be evaluated with high confidence, given only a collection of past trajectories. Together, these ensure that we avoid proposing unreasonable policies in high-risk settings. We demonstrate our approach to reward design on synthetic domains as well as in a critical care context, to guide the design of a reward function that consolidates clinical objectives to learn a policy for weaning patients from mechanical ventilation.", 
        "authors": "Niranjani Prasad|Barbara Engelhardt|Finale Doshi-Velez", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384450", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931912", 
        "title": "Defining admissible rewards for high-confidence policy evaluation in batch reinforcement learning"
      }, 
      {
        "UID": "20P02", 
        "abstract": "The abundance of modern health data provides many opportunities for the use of machine learning techniques to build better statistical models to improve clinical decision making. Predicting time-to-event distributions, also known as survival analysis, plays a key role in many clinical applications. We introduce a variational time-to-event prediction model, named Variational Survival Inference (VSI), which builds upon recent advances in distribution learning techniques and deep neural networks. VSI addresses the challenges of non-parametric distribution estimation by (i) relaxing the restrictive modeling assumptions made in classical models, and (ii) efficiently handling the censored observations, i.e., events that occur outside the observation window, all within the variational framework. To validate the effectiveness of our approach, an extensive set of experiments on both synthetic and real-world datasets is carried out, showing improved performance relative to competing solutions.", 
        "authors": "Zidi Xiu|Chenyang Tao|Ricardo Henao", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384454", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931913", 
        "title": "Variational learning of individual survival distributions"
      }, 
      {
        "UID": "20P03", 
        "abstract": "The dearth of prescribing guidelines for physicians is one key driver of the current opioid epidemic in the United States. In this work, we analyze medical and pharmaceutical claims data to draw insights on characteristics of patients who are more prone to adverse outcomes after an initial synthetic opioid prescription. Toward this end, we propose a generative model that allows discovery from observational data of subgroups that demonstrate an enhanced or diminished causal effect due to treatment. Our approach models these sub-populations as a mixture distribution, using sparsity to enhance interpretability, while jointly learning nonlinear predictors of the potential outcomes to better adjust for confounding. The approach leads to human interpretable insights on discovered subgroups, improving the practical utility for decision support.", 
        "authors": "Chirag Nagpal|Dennis Wei|Bhanukiran Vinzamuri|Monica Shekhar|Sara E. Berger|Subhro Das|Kush R. Varshney", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384456", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931914", 
        "title": "Interpretable subgroup discovery in treatment effect estimation with application to opioid prescribing guidelines"
      }, 
      {
        "UID": "20P04", 
        "abstract": "Adverse drug reactions (ADRs) are detrimental and unexpected clinical incidents caused by drug intake. The increasing availability of massive quantities of longitudinal event data such as electronic health records (EHRs) has redefined ADR discovery as a big data analytics problem, where data-hungry deep neural networks are especially suitable because of the abundance of the data. To this end, we introduce neural self-controlled case series (NSCCS), a deep learning framework for ADR discovery from EHRs. NSCCS rigorously follows a self-controlled case series design to adjust implicitly and efficiently for individual heterogeneity. In this way, NSCCS is robust to time-invariant confounding issues and thus more capable of identifying associations that reflect the underlying mechanism between various types of drugs and adverse conditions. We apply NSCCS to a large-scale real-world EHR dataset and empirically demonstrate its superior performance with comprehensive experiments on a benchmark ADR discovery task.", 
        "authors": "Wei Zhang|Zhaobin Kuang|Peggy Peissig|David Page", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384459", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931915", 
        "title": "Adverse drug reaction discovery from electronic health records with deep neural networks"
      }, 
      {
        "UID": "20P05", 
        "abstract": "Real-world predictive models in healthcare should be evaluated in terms of discrimination, the ability to differentiate between high and low risk events, and calibration, or the accuracy of the risk estimates. Unfortunately, calibration is often neglected and only discrimination is analyzed. Calibration is crucial for personalized medicine as they play an increasing role in the decision making process. Since random forest is a popular model for many healthcare applications, we propose CaliForest, a new calibrated random forest. Unlike existing calibration methodologies, CaliForest utilizes the out-of-bag samples to avoid the explicit construction of a calibration set. We evaluated CaliForest on two risk prediction tasks obtained from the publicly-available MIMIC-III database. Evaluation on these binary prediction tasks demonstrates that CaliForest can achieve the same discriminative power as random forest while obtaining a better-calibrated model evaluated across six different metrics. CaliForest will be published on the standard Python software repository and the code will be openly available on Github.", 
        "authors": "Yubin Park|Joyce C. Ho", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384461", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931916", 
        "title": "CaliForest: calibrated random forest for health data"
      }, 
      {
        "UID": "20P06", 
        "abstract": "Retinal effusions and cysts caused by the leakage of damaged macular vessels and choroid neovascularization are symptoms of many ophthalmic diseases. Optical coherence tomography (OCT), which provides clear 10-layer cross-sectional images of the retina, is widely used to screen various ophthalmic diseases. A large number of researchers have carried out relevant studies on deep learning technology to realize the semantic segmentation of lesion areas, such as effusion on OCT images, and achieved good results. However, in this field, problems of the low contrast of the lesion area and unevenness of lesion size limit the accuracy of the deep learning semantic segmentation model. In this paper, we propose a boundary multi-scale multi-task OCT segmentation network (BMM-Net) for these two challenges to segment the retinal edema area, subretinal fluid, and pigment epithelial detachment in OCT images. We propose a boundary extraction module, a multi-scale information perception module, and a classification module to capture accurate position and semantic information and collaboratively extract meaningful features. We train and verify on the AI Challenger competition dataset. The average Dice coefficient of the three lesion areas is 3.058% higher than the most commonly used model in the field of medical image segmentation and reaches 0.8222.", 
        "authors": "Ruru Zhang|Jiawen He|Shenda Shi|Haihong E|Zhonghong Ou|Meina Song", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384447", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931917", 
        "title": "BMM-Net: automatic segmentation of edema in optical coherence tomography based on boundary detection and multi-scale network"
      }, 
      {
        "UID": "20P07", 
        "abstract": "Conventional survival analysis approaches estimate risk scores or individualized time-to-event distributions conditioned on covariates. In practice, there is often great population-level phenotypic heterogeneity, resulting from (unknown) subpopulations with diverse risk profiles or survival distributions. As a result, there is an unmet need in survival analysis for identifying subpopulations with distinct risk profiles, while jointly accounting for accurate individualized time-to-event predictions. An approach that addresses this need is likely to improve the characterization of individual outcomes by leveraging regularities in subpopulations, thus accounting for population-level heterogeneity. In this paper, we propose a Bayesian nonparametrics approach that represents observations (subjects) in a clustered latent space, and encourages accurate time-to-event predictions and clusters (subpopulations) with distinct risk profiles. Experiments on real-world datasets show consistent improvements in predictive performance and interpretability relative to existing state-of-the-art survival analysis models.", 
        "authors": "Paidamoyo Chapfuwa|Chunyuan Li|Nikhil Mehta|Lawrence Carin|Ricardo Henao", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384465", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931918", 
        "title": "Survival cluster analysis"
      }, 
      {
        "UID": "20P08", 
        "abstract": "While deep learning has shown promise in the domain of disease classification from medical images, models based on state-of-the-art convolutional neural network architectures often exhibit performance loss due to dataset shift. Models trained using data from one hospital system achieve high predictive performance when tested on data from the same hospital, but perform significantly worse when they are tested in different hospital systems. Furthermore, even within a given hospital system, deep learning models have been shown to depend on hospital- and patient-level confounders rather than meaningful pathology to make classifications. In order for these models to be safely deployed, we would like to ensure that they do not use confounding variables to make their classification, and that they will work well even when tested on images from hospitals that were not included in the training data. We attempt to address this problem in the context of pneumonia classification from chest radiographs. We propose an approach based on adversarial optimization, which allows us to learn more robust models that do not depend on confounders. Specifically, we demonstrate improved out-of-hospital generalization performance of a pneumonia classifier by training a model that is invariant to the view position of chest radiographs (anterior-posterior vs. posterior-anterior). Our approach leads to better predictive performance on external hospital data than both a standard baseline and previously proposed methods to handle confounding, and also suggests a method for identifying models that may rely on confounders.", 
        "authors": "Joseph D. Janizek|Gabriel Erion|Alex J. DeGrave|Su-In Lee", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384458", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931919", 
        "title": "An adversarial approach for the robust classification of pneumonia from chest radiographs"
      }, 
      {
        "UID": "20P09", 
        "abstract": "Much work aims to explain a model's prediction on a static input. We consider explanations in a temporal setting where a stateful dynamical model produces a sequence of risk estimates given an input at each time step. When the estimated risk increases, the goal of the explanation is to attribute the increase to a few relevant inputs from the past.While our formal setup and techniques are general, we carry out an in-depth case study in a clinical setting. The goal here is to alert a clinician when a patient's risk of deterioration rises. The clinician then has to decide whether to intervene and adjust the treatment. Given a potentially long sequence of new events since she last saw the patient, a concise explanation helps her to quickly triage the alert.We develop methods to lift static attribution techniques to the dynamical setting, where we identify and address challenges specific to dynamics. We then experimentally assess the utility of different explanations of clinical alerts through expert evaluation.", 
        "authors": "Michaela Hardt|Alvin Rajkomar|Gerardo Flores|Andrew Dai|Michael Howell|Greg Corrado|Claire Cui|Moritz Hardt", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384460", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931920", 
        "title": "Explaining an increase in predicted risk for clinical alerts"
      }, 
      {
        "UID": "20P10", 
        "abstract": "We introduce SparseVM, a method that registers clinical-quality 3D MR scans both faster and more accurately than previously possible. Deformable alignment, or registration, of clinical scans is a fundamental task for many clinical neuroscience studies. However, most registration algorithms are designed for high-resolution research-quality scans. In contrast to research-quality scans, clinical scans are often sparse, missing up to 86% of the slices available in research-quality scans. Existing methods for registering these sparse images are either inaccurate or extremely slow. We present a learning-based registration method, SparseVM, that is more accurate and orders of magnitude faster than the most accurate clinical registration methods. To our knowledge, it is the first method to use deep learning specifically tailored to registering clinical images. We demonstrate our method on a clinically-acquired MRI dataset of stroke patients and on a simulated sparse MRI dataset. Our code is available as part of the VoxelMorph package at http://voxelmorph.mit.edu.", 
        "authors": "Kathleen Lewis|Natalia S. Rost|John Guttag|Adrian V. Dalca", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384462", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931921", 
        "title": "Fast learning-based registration of sparse 3D clinical images"
      }, 
      {
        "UID": "20P11", 
        "abstract": "Necrotizing enterocolitis (NEC) is a life-threatening intestinal disease that primarily affects preterm infants during their first weeks after birth. Mortality rates associated with NEC are 15-30%, and surviving infants are susceptible to multiple serious, long-term complications. The disease is sporadic and, with currently available tools, unpredictable. We are creating an early warning system that uses stool microbiome features, combined with clinical and demographic information, to identify infants at high risk of developing NEC. Our approach uses a multiple instance learning, neural network-based system that could be used to generate daily or weekly NEC predictions for premature infants. The approach was selected to effectively utilize sparse and weakly annotated datasets characteristic of stool microbiome analysis. Here we describe initial validation of our system, using clinical and microbiome data from a nested case-control study of 161 preterm infants. We show receiver-operator curve areas above 0.9, with 75% of dominant predictive samples for NEC-affected infants identified at least 24 hours prior to disease onset. Our results pave the way for development of a real-time early warning system for NEC using a limited set of basic clinical and demographic details combined with stool microbiome data.", 
        "authors": "Thomas Hooven|Yun Chao Lin|Ansaf Salleb-Aouissi", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384466", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931922", 
        "title": "Multiple instance learning for predicting necrotizing enterocolitis in premature infants using microbiome data"
      }, 
      {
        "UID": "20P12", 
        "abstract": "In this work, we examine the extent to which embeddings may encode marginalized populations differently, and how this may lead to a perpetuation of biases and worsened performance on clinical tasks. We pretrain deep embedding models (BERT) on medical notes from the MIMIC-III hospital dataset, and quantify potential disparities using two approaches. First, we identify dangerous latent relationships that are captured by the contextual word embeddings using a fill-in-the-blank method with text from real clinical notes and a log probability bias score quantification. Second, we evaluate performance gaps across different definitions of fairness on over 50 downstream clinical prediction tasks that include detection of acute and chronic conditions. We find that classifiers trained from BERT representations exhibit statistically significant differences in performance, often favoring the majority group with regards to gender, language, ethnicity, and insurance status. Finally, we explore shortcomings of using adversarial debiasing to obfuscate subgroup information in contextual word embeddings, and recommend best practices for such deep embedding models in clinical settings.", 
        "authors": "Haoran Zhang|Amy X. Lu|Mohamed Abdalla|Matthew McDermott|Marzyeh Ghassemi", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384448", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931923", 
        "title": "Hurtful words: quantifying biases in clinical contextual word embeddings"
      }, 
      {
        "UID": "20P13", 
        "abstract": "Single-cell RNA sequencing (scRNA-seq) has revolutionized bio-logical discovery, providing an unbiased picture of cellular heterogeneity in tissues. While scRNA-seq has been used extensively to provide insight into health and disease, it has not been used for disease prediction or diagnostics. Graph Attention Networks have proven to be versatile for a wide range of tasks by learning from both original features and graph structures. Here we present a graph attention model for predicting disease state from single-cell data on a large dataset of Multiple Sclerosis (MS) patients. MS is a disease of the central nervous system that is difficult to diagnose. We train our model on single-cell data obtained from blood and cerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy adults (HA), resulting in 66,667 individual cells. We achieve 92% accuracy in predicting MS, outperforming other state-of-the-art methods such as a graph convolutional network, random forest, and multi-layer perceptron. Further, we use the learned graph attention model to get insight into the features (cell types and genes) that are important for this prediction. The graph attention model also allow us to infer a new feature space for the cells that emphasizes the difference between the two conditions. Finally we use the attention weights to learn a new low-dimensional embedding which we visualize with PHATE and UMAP. To the best of our knowledge, this is the first effort to use graph attention, and deep learning in general, to predict disease state from single-cell data. We envision applying this method to single-cell data for other diseases.", 
        "authors": "Neal Ravindra|Arijit Sehanobish|Jenna L. Pappalardo|David A. Hafler|David van Dijk", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384449", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931924", 
        "title": "Disease state prediction from single-cell data using graph attention networks"
      }, 
      {
        "UID": "20P14", 
        "abstract": "The International Classification of Disease (ICD) is a widely used diagnostic ontology for the classification of health disorders and a valuable resource for healthcare analytics. However, ICD is an evolving ontology and subject to periodic revisions (e.g. ICD-9-CM to ICD-10-CM) resulting in the absence of complete cross-walks between versions. While clinical experts can create custom mappings across ICD versions, this process is both time-consuming and costly. We propose an automated solution that facilitates interoperability without sacrificing accuracy.Our solution leverages the SNOMED-CT ontology whereby medical concepts are organised in a directed acyclic graph. We use this to map ICD-9-CM to ICD-10-CM by associating codes to clinical concepts in the SNOMED graph using a nearest neighbors search in combination with natural language processing. To assess the impact of our method, the performance of a gradient boosted tree (XGBoost) developed to classify patients with Exocrine Pancreatic Insufficiency (EPI) disorder, was compared when using features constructed by our solution versus clinically-driven methods. This dataset comprised of 23, 204 EPI patients and 277, 324 non-EPI patients with data spanning from October 2011 to April 2017. Our algorithm generated clinical predictors with comparable stability across the ICD-9-CM to ICD-10-CM transition point when compared to ICD-9-CM/ICD-10-CM mappings generated by clinical experts. Preliminary modeling results showed highly similar performance for models based on the SNOMED mapping vs clinically defined mapping (71% precision at 20% recall for both models). Overall, the framework does not compromise on accuracy at the individual code level or at the model-level while obviating the need for time-consuming manual mapping.", 
        "authors": "Shaun Gupta|Frederik Dieleman|Patrick Long|Orla Doyle|Nadejda Leavitt", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384453", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931925", 
        "title": "Using SNOMED to automate clinical concept mapping"
      }, 
      {
        "UID": "20P15", 
        "abstract": "Systematic review (SR) is an essential process to identify, evaluate, and summarize the findings of all relevant individual studies concerning health-related questions. However, conducting a SR is labor-intensive, as identifying relevant studies is a daunting process that entails multiple researchers screening thousands of articles for relevance. In this paper, we propose MMiDaS-AE, a Multi-modal Missing Data aware Stacked Autoencoder, for semi-automating screening for SRs. We use a multi-modal view that exploits three representations, of: 1) documents, 2) topics, and 3) citation networks. Documents that contain similar words will be nearby in the document embedding space. Models can also exploit the relationship between documents and the associated SR MeSH terms to capture article relevancy. Finally, related works will likely share the same citations, and thus closely related articles would, intuitively, be trained to be close to each other in the embedding space. However, using all three learned representations as features directly result in an unwieldy number of parameters. Thus, motivated by recent work on multi-modal auto-encoders, we adopt a multi-modal stacked autoencoder that can learn a shared representation encoding all three representations in a compressed space. However, in practice one or more of these modalities may be missing for an article (e.g., if we cannot recover citation information). Therefore, we propose to learn to impute the shared representation even when specific inputs are missing. We find this new model significantly improves performance on a dataset consisting of 15 SRs compared to existing approaches.", 
        "authors": "Eric W. Lee|Byron C. Wallace|Karla I. Galaviz|Joyce C. Ho", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384463", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931926", 
        "title": "MMiDaS-AE: multi-modal missing data aware stacked autoencoder for biomedical abstract screening"
      }, 
      {
        "UID": "20P16", 
        "abstract": "Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.", 
        "authors": "Luke Oakden-Rayner|Jared Dunnmon|Gustavo Carneiro|Christopher Re", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384468", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931927", 
        "title": "Hidden stratification causes clinically meaningful failures in machine learning for medical imaging"
      }, 
      {
        "UID": "20P17", 
        "abstract": "Automated assessment of rehabilitation exercises using machine learning has a potential to improve current rehabilitation practices. However, it is challenging to completely replicate therapist's decision making on the assessment of patients with various physical conditions. This paper describes an interactive machine learning approach that iteratively integrates a data-driven model with expert's knowledge to assess the quality of rehabilitation exercises. Among a large set of kinematic features of the exercise motions, our approach identifies the most salient features for assessment using reinforcement learning and generates a user-specific analysis to elicit feature relevance from a therapist for personalized rehabilitation assessment. While accommodating therapist's feedback on feature relevance, our approach can tune a generic assessment model into a personalized model. Specifically, our approach improves performance to predict assessment from 0.8279 to 0.9116 average F1-scores of three upper-limb rehabilitation exercises (p < 0.01). Our work demonstrates that machine learning models with feature selection can generate kinematic feature-based analysis as explanations on predictions of a model to elicit expert's knowledge of assessment, and how machine learning models can augment with expert's knowledge for personalized rehabilitation assessment.", 
        "authors": "Min Hun Lee|Daniel P. Siewiorek|Asim Smailagic|Alexandre Bernardino|Sergi Berm\u00fadez i Badia", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384452", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931928", 
        "title": "Interactive hybrid approach to combine machine and human intelligence for personalized rehabilitation assessment"
      }, 
      {
        "UID": "20P18", 
        "abstract": "Accurately extracting medical entities from social media is challenging because people use informal language with different expressions for the same concept, and they also make spelling mistakes. Previous work either focused on specific diseases (e.g., depression) or drugs (e.g., opioids) or, if working with a wide-set of medical entities, only tackled individual and small-scale benchmark datasets (e.g., AskaPatient). In this work, we first demonstrated how to accurately extract a wide variety of medical entities such as symptoms, diseases, and drug names on three benchmark datasets from varied social media sources, and then also validated this approach on a large-scale Reddit dataset.We first implemented a deep-learning method using contextual embeddings that upon two existing benchmark datasets, one containing annotated AskaPatient posts (CADEC) and the other containing annotated tweets (Micromed), outperformed existing state-of-the-art methods. Second, we created an additional benchmark dataset by annotating medical entities in 2K Reddit posts (made publicly available under the name of MedRed) and showed that our method also performs well on this new dataset.Finally, to demonstrate that our method accurately extracts a wide variety of medical entities on a large scale, we applied the model pre-trained on MedRed to half a million Reddit posts. The posts came from disease-specific subreddits so we could categorise them into 18 diseases based on the subreddit. We then trained a machine-learning classifier to predict the post's category solely from the extracted medical entities. The average F1 score across categories was .87. These results open up new cost-effective opportunities for modeling, tracking and even predicting health behavior at scale.", 
        "authors": "Sanja Scepanovic|Enrique Martin-Lopez|Daniele Quercia|Khan Baykaner", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384467", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931929", 
        "title": "Extracting medical entities from social media"
      }, 
      {
        "UID": "20P19", 
        "abstract": "While machine learning is rapidly being developed and deployed in health settings such as influenza prediction, there are critical challenges in using data from one environment to predict in another due to variability in features. Even within disease labels there can be differences (e.g. \"fever\" may mean something different reported in a doctor's office versus in an online app). Moreover, models are often built on passive, observational data which contain different distributions of population subgroups (e.g. men or women). Thus, there are two forms of instability between environments in this observational transport problem. We first harness substantive knowledge from health research to conceptualize the underlying causal structure of this problem in a health outcome prediction task. Based on sources of stability in the model and the task, we posit that we can combine environment and population information in a novel population-aware hierarchical Bayesian domain adaptation framework that harnesses multiple invariant components through population attributes when needed. We study the conditions under which invariant learning fails, leading to reliance on the environment-specific attributes. Experimental results for an influenza prediction task on four datasets gathered from different contexts show the model can improve prediction in the case of largely unlabelled target data from a new environment and different constituent population, by harnessing both environment and population invariant information. This work represents a novel, principled way to address a critical challenge by blending domain (health) knowledge and algorithmic innovation. The proposed approach will have significant impact in many social settings wherein who the data comes from and how it was generated, matters.", 
        "authors": "Vishwali Mhasawade|Nabeel Abdur Rehman|Rumi Chunara", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384451", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931930", 
        "title": "Population-aware hierarchical bayesian domain adaptation via multi-component invariant learning"
      }, 
      {
        "UID": "20P20", 
        "abstract": "Phenotyping electronic health records (EHR)focuses on defining meaningful patient groups (e.g., heart failure group and diabetes group) and identifying the temporal evolution of patients in those groups. Tensor factorization has been an effective tool for phenotyping. Most of the existing works assume either a static patient representation with aggregate data or only model temporal data. However, real EHR data contain both temporal (e.g., longitudinal clinical visits) and static information (e.g., patient demographics), which are difficult to model simultaneously. In this paper, we propose Temporal And Static TEnsor factorization (TASTE) that jointly models both static and temporal information to extract phenotypes.TASTE combines the PARAFAC2 model with non-negative matrix factorization to model a temporal and a static tensor. To fit the proposed model, we transform the original problem into simpler ones which are optimally solved in an alternating fashion. For each of the sub-problems, our proposed mathematical re-formulations lead to efficient sub-problem solvers. Comprehensive experiments on large EHR data from a heart failure (HF) study confirmed that TASTE is up to 14\u00d7 faster than several baselines and the resulting phenotypes were confirmed to be clinically meaningful by a cardiologist. Using 60 phenotypes extracted by TASTE, a simple logistic regression can achieve the same level of area under the curve (AUC) for HF prediction compared to a deep learning model using recurrent neural networks (RNN) with 345 features.", 
        "authors": "Ardavan Afshar|Ioakeim Perros|Haesun Park|Christopher deFilippi|Xiaowei Yan|Walter Stewart|Joyce Ho|Jimeng Sun", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384464", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931931", 
        "title": "TASTE: temporal and static tensor factorization for phenotyping electronic health records"
      }, 
      {
        "UID": "20P21", 
        "abstract": "In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.", 
        "authors": "Michael W. Dusenberry|Dustin Tran|Edward Choi|Jonas Kemp|Jeremy Nixon|Ghassen Jerfel|Katherine Heller|Andrew M. Dai", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384457", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931932", 
        "title": "Analyzing the role of model uncertainty for electronic health records"
      }, 
      {
        "UID": "20P22", 
        "abstract": "The ability of caregivers and investigators to share patient data is fundamental to many areas of clinical practice and biomedical research. Prior to sharing, it is often necessary to remove identifiers such as names, contact details, and dates in order to protect patient privacy. Deidentification, the process of removing identifiers, is challenging, however. High-quality annotated data for developing models is scarce; many target identifiers are highly heterogenous (for example, there are uncountable variations of patient names); and in practice anything less than perfect sensitivity may be considered a failure. Consequently, software for adequately deidentifying clinical data is not widely available. As a result patient data is often withheld when sharing would be beneficial, and identifiable patient data is often divulged when a deidentified version would suffice.In recent years, advances in machine learning methods have led to rapid performance improvements in natural language processing tasks, in particular with the advent of large-scale pretrained language models. In this paper we develop and evaluate an approach for deidentification of clinical notes based on a bidirectional transformer model. We propose human interpretable evaluation measures and demonstrate state of the art performance against modern baseline models. Finally, we highlight current challenges in deidentification, including the absence of clear annotation guidelines, lack of portability of models, and paucity of training data. Code to develop our model is open source and simple to install, allowing for broad reuse.", 
        "authors": "Alistair E. W. Johnson|Lucas Bulgarelli|Tom J. Pollard", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384455", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931933", 
        "title": "Deidentification of free-text medical records using pre-trained bidirectional transformers"
      }, 
      {
        "UID": "20P23", 
        "abstract": "Machine learning for healthcare researchers face challenges to progress and reproducibility due to a lack of standardized processing frameworks for public datasets. We present MIMIC-Extract, an open source pipeline for transforming the raw electronic health record (EHR) data of critical care patients from the publicly-available MIMIC-III database into data structures that are directly usable in common time-series prediction pipelines. MIMIC-Extract addresses three challenges in making complex EHR data accessible to the broader machine learning community. First, MIMIC-Extract transforms raw vital sign and laboratory measurements into usable hourly time series, performing essential steps such as unit conversion, outlier handling, and aggregation of semantically similar features to reduce missingness and improve robustness. Second, MIMIC-Extract extracts and makes prediction of clinically-relevant targets possible, including outcomes such as mortality and length-of-stay as well as comprehensive hourly intervention signals for ventilators, vasopressors, and fluid therapies. Finally, the pipeline emphasizes reproducibility and extensibility to future research questions. We demonstrate the pipeline's effectiveness by developing several benchmark tasks for outcome and intervention forecasting and assessing the performance of competitive models.", 
        "authors": "Shirly Wang|Matthew B. A. McDermott|Geeticka Chauhan|Marzyeh Ghassemi|Michael C. Hughes|Tristan Naumann", 
        "doi_link": "http://dx.doi.org/10.1145/3368555.3384469", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931934", 
        "title": "MIMIC-Extract: a data extraction, preprocessing, and representation pipeline for MIMIC-III"
      }
    ], 
    "speakers": [
      {
        "UID": "20K01", 
        "abstract": "This talk outlines two Mila projects aimed at fighting the Covid-19 pandemic which are part of Mila's AI for Humanity mission. The first one is about discovering antivirals, either via repurposing several existing drugs using graph neural networks or via discovering new drug-like molecules using reinforcement learning and docking simulations to search in the molecular space. The second project is about using machine learning to provide early warning signals to people who are contagious -- especially if they don't realize that they are -- by exchanging information between phones of users who have had dangerous contacts with each other. This extends digital contact tracing by incorporating information about symptoms, medical condition and behavior (like wearing a mask) and relies on a sophisticated epidemiological model at the individual levels in which we can simulate different individual-level and society-level strategies.", 
        "bio": "Yoshua Bengio is Professor in the Computer Science and Operations Research departments at U. Montreal, founder and scientific director of Mila and of IVADO. He is a Fellow of the Royal Society of London and of the Royal Society of Canada, has received a Canada Research Chair and a Canada CIFAR AI Chair and is a recipient of the 2018 Turing Award for pioneering deep learning, is an officer of the Order of Canada, a member of the NeurIPS advisory board, co-founder and member of the board of the ICLR conference, and program director of the CIFAR program on Learning in Machines and Brains. His goal is to contribute to uncovering the principles giving rise to intelligence through learning, as well as favour the development of AI for the benefit of all.", 
        "image": "static/images/speakers/yoshua_bengio.png", 
        "institution": "University of Montreal", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931907", 
        "speaker": "Yoshua Bengio", 
        "title": "Machine Learning Challenges in the Fight for Social Good - the Covid-19 Case", 
        "website": ""
      }, 
      {
        "UID": "20K02", 
        "abstract": "Countries in Sub-Saharan Africa are facing a double burden of infectious and noncommunicable diseases. The burden of noncommunicable diseases such as, diabetes and hypertension, are expected to continue increasing. Digital data and tools that can be used to study the patterns of health and disease in populations offer opportunities for improving public health. Digital platforms such as, social media, search engines, and internet forums, have been widely accepted in Sub-Saharan Africa for health information seeking and sharing. These tools can be used to improve public health in Sub-Saharan Africa in three ways: (1) monitoring health information seeking and providing health education, (2) monitoring risk factors, and (3) monitoring disease incidence. However, in order for these tools to be effective, it is important to consider and incorporate into analytical processes the distinct social, cultural, and economic context in Sub-Saharan African countries.", 
        "bio": "Dr. Nsoesie is an Assistant Professor of Global Health at Boston University (BU) School of Public Health. She is also a BU Data Science Faculty Fellow as part of the BU Data Science Initiative at the Hariri Institute for Computing and a Data and Innovation Fellow at The Directorate of Science, Technology and Innovation (DSTI) in the Office of the President in Sierra Leone. Dr. Nsoesie applies data science methodologies to global health problems, using digital data and technology to improve health, particularly in the realm of surveillance of chronic and infectious diseases. She has worked with local public health departments in the United States and international organizations. She completed her postdoctoral studies at Harvard Medical School, and her PhD in Computational Epidemiology from the Genetics, Bioinformatics and Computational Biology program at Virginia Tech. She also has an MS in Statistics and a BS in Mathematics. She is the founder of Reth\u00e9 \u2013  an initiative focused on providing scientific writing tools and resources to student communities in Africa in order to increase representation in scientific publications. She has written for NPR, The Conversation, Public Health Post and Quartz. Dr. Nsoesie was born and raised in Cameroon.", 
        "image": "static/images/speakers/elaine_nsoesie.jpg", 
        "institution": "Boston University", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931908", 
        "speaker": "Elaine Nsoesie", 
        "title": "Digital Platforms & Public Health in Africa", 
        "website": ""
      }, 
      {
        "UID": "20K03", 
        "abstract": "The massive size of the health care sector make data science applications in this space particularly salient for social policy. An overarching theme of this keynote is that developing machine learning methodology tailored to specific substantive health problems and the associated electronic health data is critical given the stakes involved, rather than eschewing complexity in simplified scenarios that may no longer represent an actual real-world problem.", 
        "bio": "Sherri Rose, Ph.D. is an Associate Professor of Health Care Policy at Harvard Medical School and Co-Director of the Health Policy Data Science Lab. Her research in health policy focuses on risk adjustment, comparative effectiveness, and health program evaluation. Dr. Rose coauthored the first book on machine learning for causal inference and has published work across fields, including in Biometrics, JASA, PMLR,Journal of Health Economics, and NEJM. She currently serves as co-editor of the journal Biostatistics and is Chair-Elect of the American Statistical Association\u2019s Biometrics Section. Her honors include the ISPOR Bernie J. O\u2019Brien New Investigator Award for exceptional early career work in health economics and outcomes research and an NIH Director\u2019s New Innovator Award to develop machine learning estimators for generalizability in health policy.", 
        "image": "static/images/speakers/sherri_rose.png", 
        "institution": "Harvard Medical School", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931910", 
        "speaker": "Sherri Rose", 
        "title": "Machine Learning in Health Care: Too Important to Be a Toy Example", 
        "website": ""
      }, 
      {
        "UID": "20K04", 
        "abstract": "Details to be confirmed.", 
        "bio": "Dr. Ruslan Salakhutdinov is a UPMC professor of Computer Science at Carnegie Mellon University. He has served as an area chair for NIPS, ICML, CVPR, and ICLR. He holds a PhD from University of Toronto and completed postdoctoral training at Massachusetts Institute of Technology.", 
        "image": "static/images/speakers/ruslan_salakhutdinov.png", 
        "institution": "Carnegie Mellon University", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931911", 
        "speaker": "Ruslan Salakhutdinov", 
        "title": "Incorporating Domain Knowledge into Deep Learning Models", 
        "website": ""
      }, 
      {
        "UID": "20K05", 
        "abstract": "In this session we will explore strategies for, and issues involved in, bringing Artificial Intelligence (AI) technologies to the clinic, safely and ethically. We will discuss the characteristics of a sound data strategy for powering a machine learning (ML) health system. The session introduces a frame-work for analyzing the utility of ML models in healthcare and discusses the implicit assumptions in aligning incentives for AI guided healthcare actions.", 
        "bio": "Dr. Nigam Shah is Associate Professor of Medicine (Biomedical Informatics) at Stanford University, and serves as the Associate CIO for Data Science for Stanford Health Care. Dr. Shah\u2019s research focuses on combining machine learning and prior knowledge in medical ontologies to enable the learning health system. Dr. Shah was elected into the American College of Medical Informatics (ACMI) in 2015 and is inducted into the American Society for Clinical Investigation (ASCI) in 2016. He holds an MBBS from Baroda Medical College, India, a PhD from Penn State University and completed postdoctoral training at Stanford University.", 
        "image": "static/images/speakers/nigam_shah.png", 
        "institution": "Stanford University", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931909", 
        "speaker": "Nigam Shah", 
        "title": "A framework for shaping the future of AI in healthcare", 
        "website": ""
      }
    ], 
    "symposiums": [
      {
        "UID": "20S01", 
        "abstract": "Serena Jeblee's (University of Toronto, Expected Aug 2020) research focuses on clinical natural language processing (NLP), with a special focus on the extraction of a normalized Cause of Death (CoD) from verbal autopsy reports. This research would be especially impactful in low to middle income countries, where verbal autopsy reports are common, and physical autopsies or medically certified causes of death are less common. Serena approaches this problem by first extracting a temporally ordered list of symptoms from the verbal autopsy report, then uses these to construct a more accurate assessment of the overall CoD diagnosis. Serena's other work focuses on other clinical NLP tasks, including automatic extraction of pertinent information from provider-patient dialogs.", 
        "authors": "Serena Jeblee", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931967", 
        "title": "Doctoral Symposium Talk: Serena Jeblee"
      }, 
      {
        "UID": "20S02", 
        "abstract": "Dr. Serifat Folorunso's (University of Ibadan, 2019) research focuses on augmented survival data analysis using modified generalized gamma mixture cure models (GGMCMs) for cancer research.  In particular, Dr. Folorunso's work examines generalizing traditional GGMCMs to better account for the acute-asymmetry in survival data by using a gamma link function. Dr. Folorunso's model demonstrated superior performance to a traditional GGMCM as well as other kinds of survival mixture-cure models on an ovarian cancer dataset from University College Hospital, Ibadan. Dr. Folorunso's has also investigated works examining additional aspects of survival models, as well as social determinants and impacts of neonatal health.", 
        "authors": "Serifat Folorunso", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931968", 
        "title": "Doctoral Symposium Talk: Serifat Folorunso"
      }, 
      {
        "UID": "20S03", 
        "abstract": "Dr. Savannah Bergquist's (Harvard University, 2019) research focuses on accounting for missing not at random (MNAR) data in health contexts, specifically insurance plan payment policies and lung cancer staging from insurance claims data. In the former analyses, Dr. Bergquist's work uses missingness sensitive ML methods to examine the contribution of various current practices to problematic incentives in medicare plan payment policies, and to suggest improvement. In the latter research, Dr. Bergquist focuses on predicting a clinically meaningful lung cancer staging system using classification models. Dr. Bergquist also has examined other aspects of health insurance plan design and analysis.", 
        "authors": "Savannah Bergquist", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931970", 
        "title": "Doctoral Symposium Talk: Savannah Bergquist"
      }, 
      {
        "UID": "20S04", 
        "abstract": "Paidamoyo Chapfuwa's (Duke University, Expected 2021) research focuses on bringing modern machine learning approaches to survival analysis, i.e, causal inference, generative modeling, and Bayesian nonparametric. In particular, Paidamoyo's work examines generative methods for high-performance (accurate, calibrated, uncertainty-aware predictions) survival models. Moreover, her work introduces an adversarial distribution matching approach and a novel covariate-conditional Kaplan-Meier estimator, accounting for the predictive uncertainty in survival model calibration. In  addition, her work also enables an interpretable time-to-event driven clustering method using a Bayesian nonparametric stick-breaking representation of the Dirichlet Process that represents patients in a clustered latent space. Recently,  Paidamoyo\u2019s work has explored a unified framework for individualized treatment effect estimation for survival outcomes from observation data.", 
        "authors": "Paidamoyo Chapfuwa", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931971", 
        "title": "Doctoral Symposium Talk: Paidamoyo Chapfuwa"
      }, 
      {
        "UID": "20S05", 
        "abstract": "Primoz Kocbek's (University of Maribor, Expected 2021) research focuses on interpretability and the use of synthetic data in machine learning models processing electronic health record (EHR) data. In particular, Primoz's research examined and provided a more nuanced analysis of the kinds of interpretability enabled by various kinds of models, including classifications of models as providing local vs. global or model-dependent vs. model-agnostic interpretability. Primoz also hopes to extend his research in the future with the use of synthetic data as additional structure to data, primarily leveraging the natural graph structure of some subsets of EHR data to improve predictive power.", 
        "authors": "Primoz Kocbek", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931972", 
        "title": "Doctoral Symposium Talk: Primoz Kocbek"
      }, 
      {
        "UID": "20S06", 
        "abstract": "Jill Furzer's (University of Toronto, Expected 2020) research focuses on combining ensemble learning methods with an economics causal inference tool-kit to predict mental health risk in childhood, assess drivers of marginal misdiagnosis, and understand long-term socioeconomic implications of missed, late or low-value diagnoses. Jill compares classic regression with regularized regression and gradient boosted trees to estimate latent mental health risk in childhood in a nationally representative longitudinal health survey dataset, and further examines how sensitive these models are to protected subgroup information, including gender, rural v. urban, and socioeconomic status. Jill's past research has further focused on modelling the cost-effectiveness of various pediatric oncology screening guidelines and treatments.", 
        "authors": "Jill Furzer", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931974", 
        "title": "Doctoral Symposium Talk: Jill Furzer"
      }, 
      {
        "UID": "20S07", 
        "abstract": "Dr. Hasna Njah's (University of Sfax, 2019) research focuses on learning bayesian networks (BNs) for health applications in the context of high-dimensional data. In particular, Dr. Njah's research proposes a new kind of BN, called a Bayesian Network Abstraction (BNA) framework, which uses latent variables to ameliorate the computational and optimization difficulties imposed by high-dimensional data. The BNA framework first uses dependency-based feature clustering algorithms to cluster input variables, followed by learning to summarize each cluster in a separate latent variable, thereby realizing the entire network in a hierarchical clustering & summarization BN, with the overall system learned using the greedy equilibrium criteria and hierarchical expectation maximization. In other work, Dr. Njah has focused on applying BNs to protein-protein interaction data and gene regulatory networks. ", 
        "authors": "Hasna Njah", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931976", 
        "title": "Doctoral Symposium Talk: Hasna Njah"
      }, 
      {
        "UID": "20S08", 
        "abstract": "Vinyas Harish's (University of Toronto, Expected MD/PhD 2025) research focuses on the ways in which machine learning can complement traditional epidemiological perspectives and methods applied at the population and clinical levels, with an emphasis on promoting health systems resilience in the context of emergencies. Vinyas explores these topics in several ways, including a qualitative study on the ethics of private sector ML4H collaborations with stakeholders across technical, ethics/governance, and clinical domains, an examination of the utility of pandemic preparedness indices through cluster analysis, and the high-resolution prediction of COVID-19 transmission using mobility data and environmental covariates. Historically, Vinyas has also examined medical device safety and feasibility testing as well as the efficacy of novel methods for teaching clinicians image-guided procedures.", 
        "authors": "Vinyas Harish", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931977", 
        "title": "Doctoral Symposium Talk: Vinyas Harish"
      }, 
      {
        "UID": "20S09", 
        "abstract": "Haohan Wang's (Carnegie Mellon University, Expected 2021) research focuses on the systematic development of trustworthy machine learning (ML) systems that can be deployed to answer biomedical questions in the real-world scenarios, consistently responding over significant variations of the data. In particular, Haohan's work focuses on improving robustness of ML models to dataset shift, specifically towards the application of early prediction of Alzheimer's disease from genetic and imaging data. Haohan's methods focus on using a nuanced understanding of the data generative process in order to better account for expected distributional shifts, yielding more robust and interpretable models of Alzheimer's diagnosis. In other work, Haohan has also investigated the use of ML methods on genomic and transcriptomic data for biomedical applications.", 
        "authors": "Haohan Wang", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931978", 
        "title": "Doctoral Symposium Talk: Haohan Wang"
      }, 
      {
        "UID": "20S10", 
        "abstract": "Mamadou Lamine MBOUP's (University of Thies, Expected 2022) research focuses on using ML methods over ultrasound data to perform early diagnosis and identification of liver damage within chronic liver disease patients and to classify said patients according to their severity. Especially in areas where chronic liver diseases, such as hepatitis, are prevalent, and liver cirrhosis and cancer are a significant health burden on the community, using ML methods to perform early diagnosis of these syndromes based on a low-cost modality like ultrasound would be extremely impactful. Mamdou's work investigates using supervised and unsupervised classical and deep learning methods to solve this problem, using data from a cohort of patients at the Aristide Le Dantec University Hospital Center. In past work, Mamadou has investigated algorithms for image compression, as well as investigated other health tasks in the cancer area.", 
        "authors": "Mamadou Lamine MBOUP", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931979", 
        "title": "Doctoral Symposium Talk: Mamadou Lamine MBOUP"
      }, 
      {
        "UID": "20S11", 
        "abstract": "Tulika Kakati's (Tezpur University, Expected 2020) research focuses on gene expression analysis using ML to identify biomarkers across disease state and the cell cycle. Tulika's work has used novel clustering methods and identification of border genes for co-expression analysis, as well as developing novel deep learning approaches to the identification of differentially expressed genes via DEGnet, validating all models across a number of gene expression datasets. Tulika has also investigated improving the computational efficiency of these methods via distributed computing, specifically with regards to the application of their clustering algorithms.", 
        "authors": "Tulika Kakati", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931980", 
        "title": "Doctoral Symposium Talk: Tulika Kakati"
      }, 
      {
        "UID": "20S12", 
        "abstract": "Nirvana Nursimulu's (University of Toronto, Expected 2021) research focuses on methods for computationally analyzing metabolic networks, with applications towards understanding pathogen growth in pursuit of drug development. Nirvana has examined the enzyme annotation problem, specifically focusing on producing methods that yield lower false positives than traditional similarity search metrics while considering full sequence diversity within enzyme classes. In addition, Nirvana has developed an automated pipeline for enzyme annotation and reconstruction of a metabolic model, focusing on increasing model coverage in order to yield more realistic simulations. In other work, Nirvana has also investigated more traditional microbiology across various pathogens.", 
        "authors": "Nirvana Nursimulu", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931981", 
        "title": "Doctoral Symposium Talk: Nirvana Nursimulu"
      }, 
      {
        "UID": "20S13", 
        "abstract": "Rohit Bhattacharya's (Johns Hopkins University, Expected 2021) research focuses on the development of causal methods that correct for understudied but ubiquitous sources of bias that arise during the course of data analyses, including data dependence, non-ignorable missingness, and model misspecification, in the study of infectious diseases. Rohit approaches these problems by developing novel graphical modeling techniques that can detect and correct for such sources of bias while providing the investigator with clear and interpretable representations of the underlying data dependence or missingness process. In dealing with model misspecification, Rohit has recently developed algorithms that yield doubly robust and efficient semi-parametric estimators for a wide class of causal graphical models, despite the presence of unmeasured confounders. In other work, Rohit has performed several investigations in oncology applications.", 
        "authors": "Rohit Bhattacharya", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931983", 
        "title": "Doctoral Symposium Talk: Rohit Bhattacharya"
      }, 
      {
        "UID": "20S14", 
        "abstract": "Kaspar M\u00e4rtens's (University of Oxford, Expected 2020) research focuses on enabling feature-level interpretability in non-linear latent variable models via a synthesis of statistical and machine learning techniques. In particular, Kaspar designs novel latent variable, non-linear dimensionality reduction models that allow for feature-level interpretability, focusing primarily on gaussian process latent variable models (GPLVMs) and variational autoencoders (VAEs), specifically augmenting these models with ideas from classical statistics, such as the functional analysis of variance (ANOVA) decomposition or probabilistic clustering algorithms. The results of these works are a class of models for flexible non-linear dimensionality reduction together with explainability, providing a mechanism to gain insights into what the model has learnt in terms of the observed features. In other work, Kaspar has examined genomic problems and applications of MCMC sampling.", 
        "authors": "Kaspar M\u00e4rtens", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931984", 
        "title": "Doctoral Symposium Talk: Kaspar M\u00e4rtens"
      }, 
      {
        "UID": "20S15", 
        "abstract": "Luis Oala's (Fraunhofer Heinrich Hertz Institute, Expected 2021) research focuses on gaining a better understanding about the vulnerabilities of deep neural networks and finding tests to make these vulnerabilities visible, primarily through the lens of uncertainty quantification. Together with his research group, Luis has developed an effective and modular alarm system for image reconstruction DNNs. The alarm system, called Interval Neural Networks, allows for high-resolution error heatmaps during inference for use cases such as CT image reconstruction. As co-chair of the Working Group on Data and AI Solution Assessment Methods in the ITU/WHO Focus Group on AI4H (FG-AI4H), he also leads a group of interdisciplinary experts working towards a standardized assessment framework for the evaluation of health AIs", 
        "authors": "Luis Oala", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931985", 
        "title": "Doctoral Symposium Talk: Luis Oala"
      }
    ], 
    "tutorials": [
      {
        "UID": "20T01", 
        "abstract": "Survival analysis is used for predicting time-to-event outcomes, such as how long a patient will stay in the hospital, or when the recurrence of a tumor will likely happen. This tutorial aims to go over the basics of survival analysis, how it is used in healthcare, and some of its recent methodological advances from the ML community. We will also discuss open challenges. NOTE: This tutorial has a corresponding notebook: <a href=\"https://sites.google.com/view/chil-survival\" target=\"_blank\">https://sites.google.com/view/chil-survival</a>.", 
        "authors": "George H. Chen|Jeremy C. Weiss", 
        "bio": "", 
        "rocketchat_id": "", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931962", 
        "title": "A Tour of Survival Analysis, from Classical to Modern"
      }, 
      {
        "UID": "20T02", 
        "abstract": "In this tutorial, we will describe population and public health and their essential role in a comprehensive strategy to improve health. We will illustrate state of the art data and modeling approaches in population and public health. In doing so, we will identify overlaps with and open questions relevant to machine learning, causal inference and fairness.", 
        "authors": "Vishwali Mhasawade|Yuan Zhao|Rumi Chunara", 
        "bio": "", 
        "rocketchat_id": "", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931964", 
        "title": "Population and public health: challenges and opportunities"
      }, 
      {
        "UID": "20T03", 
        "abstract": "With today's publicly available, de-identified clinical datasets, it is possible to ask questions  like, \u201cCan an algorithm read an electrocardiogram as well as a cardiologist can?\u201d However, other kinds of questions like, \u201cDoes this ECG relate to a later cardiac arrest?\u201d can\u2019t be answered with the limited public data available to us today. Research using private datasets gives us reason to be optimistic, but progress will be slow unless suitable de-identified datasets become open, allowing researchers to efficiently collaborate and compete. Learn about an effort underway at the University of Chicago, led by Ziad Obermeyer, Sendhil Mullainathan, and their team, to provide a secure and public \u201cImageNet for clinical data\u201d that balances the concerns of patients, healthcare institutions, and researchers.", 
        "authors": "Ziad Obermeyer|Katy Haynes|Amy Pitelka|Josh Risley|Katie Lin", 
        "bio": "", 
        "rocketchat_id": "", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931961", 
        "title": "Public Health Datasets for Deep Learning: Challenges and Opportunities"
      }, 
      {
        "UID": "20T04", 
        "abstract": "This tutorial will be styled as a graduate lecture about medical imaging with deep learning. This will cover the background of popular medical image domains (chest X-ray and histology) as well as methods to tackle multi-modality/view, segmentation, and counting tasks. These methods will be covered in terms of architecture and objective function design. Also, a discussion about incorrect feature attribution and approaches to mitigate the issue. Prerequisites: basic knowledge of computer vision (CNNs) and machine learning (regression, gradient descent).", 
        "authors": "Joseph Paul Cohen", 
        "bio": "", 
        "rocketchat_id": "", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931963", 
        "title": "State of the Art Deep Learning in Medical Imaging"
      }, 
      {
        "UID": "20T05", 
        "abstract": "Despite a wealth of data, only a small fraction of decisions in critical care are evidence based. In this tutorial we will start with the conception of an idea, solidify the hypothesis, operationalize the concepts involved, and execute the study in a reproducible and communicable fashion. We will run our study on MIMIC-IV, an update to MIMIC-III, and cover some of the exciting additions in the new database. This tutorial will be interactive and result in a study performed end-to-end in a Jupyter notebook. Technical expertise is not required, as we will form groups based on skill level.", 
        "authors": "Alistair Johnson", 
        "bio": "", 
        "rocketchat_id": "", 
        "slideslive_active_date": "", 
        "slideslive_id": "38931965", 
        "title": "Analyzing critical care data, from speculation to publication, starring MIMIC-IV (Part 1)"
      }, 
      {
        "UID": "20T06", 
        "abstract": "Despite a wealth of data, only a small fraction of decisions in critical care are evidence based. In this tutorial we will start with the conception of an idea, solidify the hypothesis, operationalize the concepts involved, and execute the study in a reproducible and communicable fashion. We will run our study on MIMIC-IV, an update to MIMIC-III, and cover some of the exciting additions in the new database. This tutorial will be interactive and result in a study performed end-to-end in a Jupyter notebook. Technical expertise is not required, as we will form groups based on skill level.", 
        "authors": "Alistair Johnson", 
        "bio": "", 
        "rocketchat_id": "", 
        "slideslive_active_date": "", 
        "slideslive_id": "38932058", 
        "title": "Analyzing critical care data, from speculation to publication, starring MIMIC-IV (Part 2)"
      }
    ], 
    "workshops": [
      {
        "UID": "20W01", 
        "abstract": "Small datasets form a significant portion of releasable data in high sensitivity domains such as healthcare. But, providing differential privacy for small dataset release is a hard task, where current state-of-the-art methods suffer from severe utility loss. As a solution, we propose DPRP (Differentially Private Data Release via Random Projections), a reconstruction based approach for releasing differentially private small datasets. DPRP has several key advantages over the state-of-the-art. Using seven diverse real-life clinical datasets, we show that DPRP outperforms the current state-of-the-art on a variety of tasks, under varying conditions, and for all privacy budgets.", 
        "authors": "Lovedeep Gondara|Ke Wang", 
        "slideslive_id": "38931935", 
        "title": "Differentially Private \"Small\" Dataset Release Using Random Projections"
      }, 
      {
        "UID": "20W03", 
        "abstract": "Reinforcement Learning (RL) has recently been applied to several problems in healthcare, with a particular focus in offline learning in observational data. RL relies on the use of latent states that embed sequential observations in such a way that the embedding is sufficient to approximately predict the next observation. but the appropriate construction of such states in healthcare settings is an open question, as the variation in steady-state human physiology is poorly-understood. In this work, we evaluate several information encoding schemes for offline RL using data from electronic health records (EHR). We use observations from septic patients in the MIMIC-III intensive care unit dataset, and evaluate the predictive performance of four embedding approaches in two tasks: predicting the next observation, and predicting a ``k-step'' look ahead or roll out. Our experiments highlight that the best performing state representation learning approaches utilize higher dimension recurrent neural architectures, and demonstrate that incorporating additional context with the state representation when predicting the next observation.", 
        "authors": "Taylor Killian|Jayakumar Subramanian|Mehdi Fatemi|Marzyeh Ghassemi", 
        "slideslive_id": "38931937", 
        "title": "Learning Representations for Prediction of Next Patient State"
      }, 
      {
        "UID": "20W04", 
        "abstract": "Capturing the inter-dependencies among multiple types of clinically-critical events is critical not only to accurate future event prediction, but also to better treatment planning. In this work, we propose a deep latent state-space generative model to capture the interactions among different types of correlated clinical events (e.g., kidney failure, mortality) by explicitly modeling the temporal dynamics of patients' latent states. Based on these learned patient states, we further develop a new general discrete-time formulation of the hazard rate function to estimate the survival distribution of patients with significantly improved accuracy. Extensive evaluations over real EMR data show that our proposed model compares favorably to various state-of-the-art baselines. Further our method also uncovers meaningful insights about the latent correlation among mortality and different types of organ failures.", 
        "authors": "Yuan Xue|Denny Zhou|Nan Du|Andrew M. Dai|Zhen Xu|Kun Zhang|Claire Cui", 
        "slideslive_id": "38931938", 
        "title": "Deep State-Space Generative Model For Correlated Time-to-Event Predictions"
      }, 
      {
        "UID": "20W05", 
        "abstract": "Survival function estimation is used in many disciplines, but it is most common in medical analytics in the form of the Kaplan-Meier estimator. Sensitive data (patient records) is used in the estimation without any explicit control on the information leakage, which is a significant privacy concern. We propose a first differentially private estimator of the survival function and show that it can be easily extended to provide differentially private confidence intervals and test statistics without spending any extra privacy budget. We further provide extensions for differentially private estimation of the competing risk cumulative incidence function, Nelson-Aalen's estimator for the hazard function, etc. Using eleven real-life clinical datasets, we provide empirical evidence that our proposed method provides good utility while simultaneously providing strong privacy guarantees.", 
        "authors": "Lovedeep Gondara|Ke Wang", 
        "slideslive_id": "38931939", 
        "title": "Differentially Private Survival Function Estimation"
      }, 
      {
        "UID": "20W07", 
        "abstract": "As machine learning has become increasingly applied to medical imaging data, noise in training labels has emerged as an important challenge. Variability in diagnosis of medical images is well established; in addition, variability in training and attention to task among medical labelers may exacerbate this issue. Methods for identifying and mitigating the impact of low quality labels have been studied, but are not well characterized in medical imaging tasks. For instance, Noisy Cross-Validation splits the training data into halves, and has been shown to identify low-quality labels in computer vision tasks; but it has not been applied to medical imaging tasks specifically. In addition, there may be concerns around label imbalance for medical image sets, where relevant pathology may be rare. In this work we introduce Stratified Noisy Cross-Validation (SNCV), an extension of noisy cross validation. SNCV allows us to measure confidence in model prediction and assign a quality score to each example; supports label stratification to handle class imbalance; and identifies likely low-quality labels to analyse the causes. In contrast to noisy cross-validation, sample selection for SNCV occurs after training two models, not during training, which simplifies application of the method. We assess performance of SNCV on diagnosis of glaucoma suspect risk (GSR) from retinal fundus photographs, a clinically important yet nuanced labeling task. Using training data from a previously-published deep learning model, we compute a continuous quality score (QS) for each training example. We relabel 1,277 low-QS examples using a trained glaucoma specialist; the new labels agree with the SNCV prediction over the initial label >85% of the time, indicating that low-QS examples appear mostly reflect labeler erors. We then quantify the impact of training with only high-QS labels, showing that strong model performance may be obtained with many fewer examples. By applying the method to randomly sub-sampled training dataset, we show that our method can reduce labelling burden by approximately 50% while achieving model performance non-inferior to using the full dataset on multiple held-out test sets.", 
        "authors": "Joy Hsu|Sonia Phene|Akinori Mitani|Jieying Luo|Naama Hammel|Jonathan Krause|Rory Sayres", 
        "slideslive_id": "38931941", 
        "title": "Improving medical annotation quality to decrease labeling burden using stratified noisy cross-validation"
      }, 
      {
        "UID": "20W08", 
        "abstract": "Modeling disease progression is an active area of research. Many computational methods for progression modeling have been developed but mostly at population levels. In this paper, we formulate a personalized disease progression modeling problem as a multi-task regression problem where the estimation of progression scores at different time points is defined as a learning task. We introduce a  Personalized Progression Modeling (PPM) scheme as a novel way to estimate personalized trajectories of disease by jointly discovering clusters of similar patients while estimating disease progression scores. The approach is formulated as an optimization problem that can be solved using existing optimization techniques. We present efficient algorithms for the PPM scheme, together with experimental results on both synthetic and real world healthcare data proving its analytical efficacy over other 4 baseline methods representing the current state of the art. On synthetic data, we showed that our algorithm achieves over 40% accuracy improvement over all the baselines. On the healthcare application PPM has a 4% accuracy improvement on average over the state-of-the-art baseline in predicting the viral infection progression. These results highlight significant modeling performance gains obtained with PPM.", 
        "authors": "Mohamed Ghalwash|Daby Sow", 
        "slideslive_id": "38931942", 
        "title": "A Multi-Task Learning Approach to Personalized Progression Modeling"
      }, 
      {
        "UID": "20W09", 
        "abstract": "Clinical notes in electronic health records contain highly heterogeneous writing styles, including non-standard terminology or abbreviations. Using these notes in predictive modeling has traditionally required preprocessing (e.g. taking frequent terms or topic modeling) that removes much of the richness of the source data. We propose a pretrained hierarchical recurrent neural network model that parses minimally processed clinical notes in an intuitive fashion, and show that it improves performance for discharge diagnosis classification tasks on the Medical Information Mart for Intensive Care III (MIMIC-III) dataset, compared to models that conduct no pretraining or that treat the notes as an unordered collection of terms. We also apply an attribution technique to examples to identify the words that the model uses to make its prediction, and show the importance of the words\u2019 nearby context.", 
        "authors": "Jonas Kemp|Alvin Rajkomar|Andrew M. Dai", 
        "slideslive_id": "38931943", 
        "title": "Improved Patient Classification with Hierarchical Language Model Pretraining over Clinical Notes"
      }, 
      {
        "UID": "20W10", 
        "abstract": "Industrial equipment, devices and patients typically undergo change from a healthy state to an unhealthy state. We develop a novel approach to detect unhealthy entities and also discover the time of change to enable deeper investigation into the cause for change. In the absence of an engineering or medical intervention, health degradation only happens in one direction --- healthy to unhealthy. Our transductive learning framework leverages this chronology of observations for learning a superior model with minimal supervision. Temporal Transduction is achieved by incorporating chronological constraints in the conventional max-margin classifier --- Support Vector Machines (SVM). We utilize stochastic gradient descent to solve the resulting optimization problem. Our experiments on publicly available benchmark datasets demonstrate the effectiveness of our approach in accurately detecting unhealthy entities with less supervision as compared to other strong baselines --- conventional and transductive SVM.", 
        "authors": "Abhay Harpale", 
        "slideslive_id": "38931944", 
        "title": "Health change detection using temporal transductive learning"
      }, 
      {
        "UID": "20W11", 
        "abstract": "In many Machine Learning applications, it is important to reduce the set of features used in training. This is especially important when different attributes have different acquisition costs, e.g., various blood tests. Cost-sensitive feature selection methods aim to select a subset of attributes that yields a performant Machine Learning model while keeping the total cost low. In this paper, we propose a Bayesian Optimization approach to this task. We explore the different subsets of available features by optimizing an evaluation function that weights the model's performance and total feature cost. We evaluate the proposed method on different UCI datasets, as well as a real-life one, and compare it to diverse feature selection approaches. Our results demonstrate that the Bayesian optimization cost-sensitive feature selection (BOCFS) can select a low-cost subset of informative features, therefore generating highly effective classifiers, and achieving state-of-the-art performance in some datasets.", 
        "authors": "Lucca G. Zenobio|Thiago N. C. Cardoso|Andrea Kauffmann|Augusto Antunes", 
        "slideslive_id": "38931945", 
        "title": "Cost-Sensitive Feature Selection Using Bayesian Optimization"
      }, 
      {
        "UID": "20W12", 
        "abstract": "With the increase in popularity of deep learning models for natural language processing (NLP) tasks in the field of Pharmacovigilance, more specifically for the identification of Adverse Drug Reactions (ADRs), there is an inherent need for large-scale social-media datasets aimed at such tasks. With most researchers allocating large amounts of time to crawl Twitter or buying expensive pre-curated datasets, then manually annotating by humans, these approaches do not scale well as more and more data keeps flowing in Twitter. In this work we re-purpose a publicly available archived dataset of more than 9.4 billion Tweets with the objective of creating a very large dataset of drug usage-related tweets. Using existing manually curated datasets from the literature, we then validate our filtered tweets for relevance using machine learning methods, with the end result of a publicly available dataset of 1,181,993 million tweets for public use. We provide all code and detailed procedure on how to extract this dataset and the selected tweet ids for researchers to use.", 
        "authors": "Ramya Tekumalla|Juan M Banda", 
        "slideslive_id": "38931946", 
        "title": "A large-scale Twitter dataset for drug safety applications mined from publicly existing resources"
      }, 
      {
        "UID": "20W13", 
        "abstract": "Clinical notes contain information about patients beyond structured data such as lab values or medications. However, clinical notes have been underused relative to structured data, because notes are high-dimensional and sparse. We aim to develop and evaluate a continuous representation of clinical notes. Given this representation, our goal is to predict 30-day hospital readmission at various timepoints of admission, including early stages and at discharge. We apply bidirectional encoder representations from transformers (BERT) to clinical text. Publicly-released BERT parameters are trained on standard corpora such as Wikipedia and BookCorpus, which differ from clinical text. We therefore pre-train BERT using clinical notes and fine-tune the network for the task of predicting hospital readmission. This defines ClinicalBERT. ClinicalBERT uncovers high-quality relationships between medical concepts, as judged by physicians. ClinicalBERT outperforms various baselines on 30-day hospital readmission prediction using both discharge summaries and the first few days of notes in the intensive care unit on various clinically-motivated metrics. The attention weights of ClinicalBERT can also be used to interpret predictions. To facilitate research, we open-source model parameters, and scripts for training and evaluation. ClinicalBERT is a flexible framework to represent clinical notes. It improves on previous clinical text processing methods and with little engineering can be adapted to other clinical predictive tasks.", 
        "authors": "Kexin Huang|Jaan Altosaar|Rajesh Ranganath", 
        "slideslive_id": "38931947", 
        "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"
      }, 
      {
        "UID": "20W14", 
        "abstract": "Problem lists are intended to provide clinicians with a relevant summary of patient medical issues and are embedded in many electronic health record systems. Despite their importance, problem lists are often cluttered with resolved or currently irrelevant conditions. In this work, we develop a novel end-to-end framework to first extract problem lists from clinical notes and subsequently use the extracted problems to predict patient outcomes. This framework is both more performant and more interpretable than existing models used within the domain, achieving an AU-ROC of 0.710 for bounceback readmission and 0.869 for in-hospital mortality occurring after ICU discharge. We identify risk factors for both readmission and mortality outcomes and demonstrate that it can be used to develop dynamic problem lists that present clinical problems along with their quantitative importance. This allows clinicians to both easily identify the relevant problems and gain insight into the factors driving the model\u2019s prediction.", 
        "authors": "Justin Lovelace|Nathan Hurley|Adrian Haimovich|Bobak Mortazavi", 
        "slideslive_id": "38931948", 
        "title": "Mining Dynamic Problem Lists from Clinical Notes for the Interpretable Prediction of Adverse Outcomes"
      }, 
      {
        "UID": "20W15", 
        "abstract": "Deep learning is increasingly common in healthcare, yet transfer learning for physiological signals (e.g., temperature, heart rate, etc.) is under-explored. Here, we present a straightforward, yet performant framework for transferring knowledge about physiological signals. Our framework is called PHASE (\\underline{PH}ysiologic\\underline{A}l \\underline{S}ignal \\underline{E}mbeddings). It i) learns deep embeddings of physiological signals and ii) predicts adverse outcomes based on the embeddings. PHASE is the first instance of deep transfer learning in a cross-hospital, cross-department setting for physiological signals. We show that PHASE's per-signal (one for each signal) LSTM embedding functions confer a number of benefits including improved performance, successful transference between hospitals, and lower computational cost.", 
        "authors": "Hugh Chen|Scott Lundberg|Gabe Erion|Jerry H. Kim|Su-In Lee", 
        "slideslive_id": "38931949", 
        "title": "Deep Transfer Learning for Physiological Signals"
      }, 
      {
        "UID": "20W16", 
        "abstract": "Machine-learned diagnosis models have shown promise as medical aides but are trained under a closed-set assumption, i.e. that models will only encounter conditions on which they have been trained. However, it is practically infeasible to obtain sufficient training data for every human condition, and once deployed such models will invariably face previously unseen conditions. We frame machine-learned diagnosis as an open-set learning problem, and study how state-of-the-art approaches compare. Further, we extend our study to a setting where training data is distributed across several healthcare sites that do not allow data pooling, and experiment with different strategies of building open-set diagnostic ensembles. Across both settings, we observe consistent gains from explicitly modeling unseen conditions, but find the optimal training strategy to vary across settings.", 
        "authors": "Viraj Prabhu|Anitha Kannan|Geoffrey J. Tso|Namit Katariya|Manish Chablani|David Sontag|Xavier Amatriain", 
        "slideslive_id": "38931950", 
        "title": "Open Set Medical Diagnosis"
      }, 
      {
        "UID": "20W17", 
        "abstract": "This paper aims to evaluate the suitability of current deep learning methods for clinical workflow especially by focusing on dermatology. Although deep learning methods have been attempted to  get dermatologist level accuracy in several individual conditions, it has not been rigorously tested for common clinical complaints. Most projects involve data acquired in well-controlled laboratory  conditions. This may not reflect regular clinical evaluation where corresponding image quality is not always ideal. We test the robustness of deep learning methods by simulating non-ideal characteristics on user submitted images of ten classes of diseases. Assessing via imitated  conditions, we have found the overall accuracy to drop and individual predictions change significantly in many cases despite of robust training.", 
        "authors": "Sourav Mishra|Subhajit Chaudhury|Hideaki Imaizumi|Toshihiko Yamasaki", 
        "slideslive_id": "38931951", 
        "title": "Assessing Robustness of Deep Learning Methods in Dermatological Workflow"
      }, 
      {
        "UID": "20W20", 
        "abstract": "Sentiment analysis is a well-researched field of machine learning and natural language processing generally concerned with determining the degree of positive or negative polarity in free text. Traditionally, such methods have focused on analyzing user opinions directed towards external entities such as products, news, or movies. However, less attention has been paid towards understanding the sentiment of human emotion in the form of internalized thoughts and expressions of self-reflection. Given the rise of public social media platforms and private online therapy services, the opportunity for designing accurate tools to quantify emotional states in is at an all-time high. Based upon findings in psychological research, in this work we propose a new type of sentiment analysis task more appropriate for assessing the valence of human emotion. Rather than assessing text on a single polarity axis ranging from positive to negative, we analyze self-expressive thoughts using a two-dimensional assignment scheme with four sentiment categories: positive, negative, both positive and negative, and neither positive nor negative. This work details the collection of a novel annotated dataset of real-world mental health therapy logs and compares several machine learning methodologies for the accurate classification of emotional valence. We found superior performance using deep transfer learning approaches, and in particular, best results were obtained using the recent breakthrough method of BERT (Bidirectional Encoder Representations from Transformers). Based on these results, it is clear that transfer learning has the potential for greatly improving the accuracy of classifiers in the mental health domain, where labeled data is often scarce. Additionally, we argue that representing emotional sentiment on decoupled valence axes via four classification labels is an appropriate modification of traditional sentiment analysis for mental health tasks.", 
        "authors": "Benjamin Shickel|Martin Heesacker|Sherry Benton|Parisa Rashidi", 
        "slideslive_id": "38931954", 
        "title": "Automated Emotional Valence Prediction in Mental Health Text via Deep Transfer Learning"
      }, 
      {
        "UID": "20W21", 
        "abstract": "Electronic Health Records (EHRs) are commonly used by the machine learning community for research on problems specifically related to health care and medicine. EHRs have the advantages that they can be easily distributed and contain many features useful for e.g. classification problems. What makes EHR data sets different from typical machine learning data sets is that they are often very sparse, due to their high dimensionality, and often contain heterogeneous data types. Furthermore, the data sets deal with sensitive information, which limits the distribution of any models learned using them, due to privacy concerns. In this work, we explore using Generative Adversarial Networks to generate synthetic, heterogeneous EHRs with the goal of using these synthetic records in place of existing data sets. We will further explore applying differential privacy (DP) preserving optimization in order to produce differentially private synthetic EHR data sets, which provide rigorous privacy guarantees, and are therefore more easily shareable. The performance (measured by AUROC, AUPRC and accuracy) of our model's synthetic, heterogeneous data is very close to the original data set (within 6.4%) for the non-DP model when tested in a binary classification task. Although incurring a 20% performance penalty, the DP synthetic data is still useful for machine learning tasks. We additionally perform a sub-population analysis and find that our model does not introduce any bias into the synthetic EHR data compared to the baseline in either male/female populations, or the 0-18, 19-50 and 51+ age groups in terms of classification performance.", 
        "authors": "Kieran Chin-Cheong|Thomas M. Sutter|Julia E. Vogt", 
        "slideslive_id": "38931955", 
        "title": "Generation of Differentially Private Heterogeneous Synthetic Electronic Health Records using GANs"
      }, 
      {
        "UID": "20W22", 
        "abstract": "Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal data about patients including clinical notes, sparse and irregularly sampled physiological time series, lab results, and more. To date, most methods designed to learn predictive models from ICU EHR data have focused on a single modality. In this paper, we leverage the recently proposed interpolation-prediction deep learning architecture as a basis for exploring how physiological time series data and clinical notes can be integrated into a unified mortality prediction model. We study both early and late fusion approaches, and demonstrate how the relative predictive value of clinical text and physiological data change over time. Our results show that a late fusion approach can provide a statistically significant improvement in mortality prediction performance over using individual modalities in isolation.", 
        "authors": "Satya Narayan Shukla|Benjamin Marlin", 
        "slideslive_id": "38931956", 
        "title": "Integrating Physiological Time Series and Clinical Notes with Deep Learning for Improved ICU Mortality Prediction"
      }, 
      {
        "UID": "20W23", 
        "abstract": "Although there have been several recent advances in the application of deep learning algorithms to chest x-ray interpretation, we identify three major challenges for the translation of chest x-ray algorithms to the clinical setting. We examine the performance of the top 10 performing models on the CheXpert challenge leaderboard on three tasks: (1) TB detection, (2) pathology detection on photos of chest x-rays, and (3) pathology detection on data from an external institution. First, we find that the top 10 chest x-ray models on the CheXpert competition achieve an average AUC of 0.851 on the task of detecting TB on two public TB datasets without fine-tuning or including the TB labels in training data. Second, we find that the average performance of the models on photos of x-rays (AUC = 0.916) is similar to their performance on the original chest x-ray images (AUC = 0.924). Third, we find that the models tested on an external dataset either perform comparably to or exceed the average performance of radiologists. We believe that our investigation will inform rapid translation of deep learning algorithms to safe and effective clinical decision support tools that can be validated prospectively with large impact studies and clinical trials.", 
        "authors": "Pranav Rajpurkar|Anirudh Joshi|Phil Chen|Anuj Pareek|Amir Kiani|Matthew Lungren|Andrew Ng|Jeremy Irvin", 
        "slideslive_id": "38931957", 
        "title": "CheXpedition: Investigating Generalization Challenges for Translation of Chest X-Ray Algorithms to the Clinical Setting"
      }, 
      {
        "UID": "20W24", 
        "abstract": "Documenting patients' interactions with health providers and institutions requires summarizing highly complex data. Medical coding reduces the dimensionality of this problem to a set of manually assigned codes that are used to bill, track patient health, and summarize a patient encounter. Incorrect coding, however, can lead to significant financial, legal, and health costs to clinics and patients. To address this, we build several deep learning models -- including transfer learning of state-of-the-art BERT models -- to predict medical codes on a novel dataset of 39,000 patient encounters. We also show through several labeling experiments that model performance is robust to subjectivity in the labels, and find that our models outperform a clinic's coding when judged against charts corrected and relabeled by an expert.", 
        "authors": "Mehmet Seflek|Wesam Elshamy|Abboud Chaballout|Ali Madani", 
        "slideslive_id": "38931958", 
        "title": "Automated Medical Coding using BERT: Benchmarking Deep Learning in the Face of Subjective Labels"
      }, 
      {
        "UID": "20W25", 
        "abstract": "Representation learning is a commonly touted goal in machine learning for healthcare, and for good reason. If we could learn a numerical encoding of clinical data which is reflective of underlying physiological similarity, this would have significant benefits both in research and application. However, many works pursuing representation learning systems evaluate only according to traditional, single-task performance metrics, and fail to assess whether or not the representations they produce actually contain generalizable signals capturing this underlying notion of similarity. In this work, we design an evaluation procedure specifically for representation learning systems, and use it to analyze the value of large-scale multi-task representation learners. We find mixed results, with multi-task representations being commonly helpful across a battery of prediction tasks and models, even while ensemble performance is often improvement by removing tasks from the trained ensemble and learned representations demonstrate no ability to cluster.", 
        "authors": "Matthew McDermott|Bret Nestor|Wancong Zhang|Peter Szolovits|Anna Goldenberg|Marzyeh Ghassemi", 
        "slideslive_id": "38931959", 
        "title": "Distracted Multi-task Learning: Addressing Negative Transfer with Fine-tuning on EHR Time-series Data"
      }, 
      {
        "UID": "20W26", 
        "abstract": "In the last few years, the FDA has begun to recognize De Novo pathways (new approval processes) for approving AI as medical devices. A major concern with this is that the review process does not adequately test for biases in these models. There are many ways in which biases can arise in data, including during data collection, training, and model deployment. In this paper, we adopt a framework for categorizing the types of bias in datasets in a fine-grained way, which enables informed, targeted interventions for each issue appropriately. From there, we propose policy recommendations to the FDA and NIH to promote the deployment of more equitable AI diagnostic systems.", 
        "authors": "Julie R Vaughn|Avital Baral|Mayukha Vadari|William Boag", 
        "slideslive_id": "38931960", 
        "title": "Dataset Bias in Diagnostic AI systems: Guidelines for Dataset Collection and Usage"
      }, 
      {
        "UID": "20W27", 
        "abstract": "Electronic records contain sequences of events, some of which take place all at once in a single visit, and others that are dispersed over multiple visits, each with a different timestamp. We postulate that fine temporal detail, e.g., whether a series of blood tests  are completed at once or in rapid succession should not alter predictions based on this data.  Motivated by this intuition, we propose models for analyzing sequences of multivariate clinical time series data that are invariant to this temporal clustering. We propose an efficient data augmentation technique that exploits the postulated temporal-clustering invariance to regularize deep neural networks optimized for several clinical prediction tasks.  We introduce two techniques to temporally coarsen (downsample) irregular time series:  (i) grouping the data points based on regularly-spaced timestamps;  and (ii) clustering them, yielding irregularly-paced timestamps.  Moreover, we propose a MultiResolution network with Shared Weights (MRSW), improving predictive accuracy by combining predictions  based on inputs sequences transformed by different coarsening operators. Our experiments show that MRSW improves the mAP on the benchmark mortality prediction task from 51.53% to 53.92%.", 
        "authors": "Mohammad Taha Bahadori|Zachary Lipton", 
        "slideslive_id": "38931987", 
        "title": "Temporal-Clustering Invariance in Irregular Healthcare Time Series"
      }, 
      {
        "UID": "20W28", 
        "abstract": "In survival analysis, deep learning approaches have recently been proposed for estimating an individual's probability of survival over some time horizon. Such approaches can capture complex non-linear relationships, without relying on restrictive assumptions regarding the specific form of the relationship between an individual's characteristics and their underlying survival process. To date, however, these methods have focused primarily on optimizing discriminative performance, and have ignored model calibration. Well-calibrated survival curves present realistic and meaningful probabilistic estimates of the true underlying survival process for an individual. However, due to the lack of ground-truth regarding the underlying stochastic process of survival for an individual, optimizing for and measuring calibration in survival analysis is an inherently difficult task. In this work, we i) propose a new loss function, for training deep nonparametric survival analysis models, that maximizes discriminative performance, subject to good calibration, and ii) present a calibration metric for survival analysis that facilitates model comparison. Through experiments on two publicly available clinical datasets, we show that our proposed approach achieves the same discriminative performance as state-of-the-art methods, while leading to over a 60% reduction in calibration error.", 
        "authors": "Fahad Kamran|Jenna Wiens", 
        "slideslive_id": "38931988", 
        "title": "Calibrated Deep Nonparametric Survival Analysis"
      }
    ]
  }, 
  "2021": {
    "highlights": "<div class=\"page-content live text-center\">\n<!-- Slides Live-->\n<div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n    <h3>Day 1 - April 8th</h3>\n    </div>\n</div>\n<div id=\"slideslive-embed\" class=\"col-md-12 col-xs-12 my-auto p-2 hide\" data-activedate=\"2021-04-14T23:59:00.00\">\n  <div id=\"presentation-embed-38954749\" class=\"slp my-auto\"></div>\n  <script src='https://slideslive.com/embed_presentation.js'></script>\n  <script>\n    embed = new SlidesLiveEmbed(\"presentation-embed-38954749\", {\n        presentationId: \"38954749\",\n        autoPlay: false, // change to true to autoplay the embedded presentation\n        verticalEnabled: true,\n        verticalWhenWidthLte: 480,\n    });\n  </script>\n</div>\n<div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n    <h3>Day 2 - April 9th</h3>\n    </div>\n</div>\n<div id=\"slideslive-embed2\" class=\"col-md-12 col-xs-12 my-auto p-2 hide\" data-activedate=\"2021-04-14T23:59:00.00\">\n  <div id=\"presentation-embed-38954751\" class=\"slp my-auto\"></div>\n  <script>\n    embed = new SlidesLiveEmbed(\"presentation-embed-38954751\", {\n        presentationId: \"38954751\",\n        autoPlay: false, // change to true to autoplay the embedded presentation\n        verticalEnabled: true,\n        verticalWhenWidthLte: 480,\n    });\n  </script>\n</div>\n</div>\n\n### Governing Board\n\n###### **General Chair**\n- Dr. Marzyeh Ghassemi of University of Toronto and Vector Institute\n###### **Program Chairs**\n- Dr. Tristan Naumann of Microsoft Research Seattle\n- Dr. Emma Pierson of Stanford University and Microsoft Research\n###### **Proceedings Chairs**\n- Emily Alsentzer of Harvard University and MIT\n- Matthew McDermott of MIT\n- Dr. George Chen of Carnegie Mellon University\n###### **Track Chairs**\n- ###### **Models and Methods**\n    * Dr. Mike Hughes of Tufts University\n    * Dr. Shalmali Joshi of Harvard University\n    * Dr. Rajesh Ranganath of New York University\n    * Dr. Rahul Krishnan of Microsoft Research, University of Toronto and Vector Institute\n- ###### **Applications and Practice**\n    * Dr. Andrew Beam of Harvard University\n    * Dr. Tom Pollard of MIT\n    * Dr. Bobak Mortazavi of Texas A&M University\n    * Dr. Uri Shalit of Technion - Israel Institute of Technology\n- ###### **Impact and Society**\n    * Dr. Alistair Johnson of The Hospital for Sick Children\n    * Dr. Rumi Chunara of New York University\n    * Dr. George Chen of Carnegie Mellon University\n###### **Communications Chairs**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge\n- Dr. Sanja \u0160\u0107epanovi\u0107 of Bell Labs Cambridge\n- Dr. Sanmi Koyejo of University of Illinois at Urbana-Champaign and Google Research\n###### **Finance Chairs**\n- Dr. Joyce Ho of Emory University\n- Dr. Brett Beaulieu-Jones of Harvard Medical School\n###### **Tutorial Chairs**\n- Irene Chen of MIT\n- Dr. Jessica Gronsbell of University of Toronto\n###### **Virtual Chairs**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge\n- Dr. Tom Pollard of MIT\n###### **Logistics Chair**\n- Tasmie Sarker of University of Toronto\n\n### Steering Committee\n\n- Dr. Yindalon Aphinyanaphongs of NYU\n- Dr. Leo Celi of MIT\n- Dr. Nigam Shah of Stanford University\n- Dr. Stephen Friend of Oxford University\n- Dr. Alan Karthikesalingam of Google Health UK\n- Dr. Ziad Obermeyer of University of California, Berkeley\n- Dr. Samantha Kleinberg of Stevens Institute of Technology\n- Dr. Anna Goldenberg of The Hospital for Sick Children Research Institute\n- Dr. Lucila Ohno-Machado of University of California, San Diego\n- Dr. Noemie Elhadad of Columbia University\n- Dr. Katherine Heller at Google Research\n- Dr. Laura Rosella of Dalla Lana School of Public Health, University of Toronto\n- Dr. Shakir Mohamed of DeepMind\n\n### Sponsors\nWe thank the Association for Computing Machinery (ACM) for sponsoring CHIL 2021, as well as the following organizations for supporting the event:\n\n- Google\n- Health[at]Scale\n- Layer6\n- Creative Destruction Lab\n- Vector Institute\n", 
    "proceedings": [
      {
        "UID": "21P01", 
        "abstract": "Electronic Health Records (EHR) are high-dimensional data with implicit connections among thousands of medical concepts. These connections, for instance, the co-occurrence of diseases and lab-disease correlations can be informative when only a subset of these variables is documented by the clinician. A feasible approach to improving the representation learning of EHR data is to associate relevant medical concepts and utilize these connections. Existing medical ontologies can be the reference for EHR structures, but they place numerous constraints on the data source. Recent progress on graph neural networks (GNN) enables end-to-end learning of topological structures for non-grid or non-sequential data. However, there are problems to be addressed on how to learn the medical graph adaptively and how to understand the effect of the medical graph on representation learning. In this paper, we propose a variationally regularized encoder-decoder graph network that achieves more robustness in graph structure learning by regularizing node representations. Our model outperforms the existing graph and non-graph based methods in various EHR predictive tasks based on both public data and real-world clinical data. Besides the improvements in empirical experiment performances, we provide an interpretation of the effect of variational regularization compared to standard graph neural network, using singular value analysis.", 
        "authors": "Weicheng Zhu (New York University) | Narges Razavian (NYU Grossman School of Medicine)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451855", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954722", 
        "title": "Variationally Regularized Graph-based Representation Learning for Electronic Health Records"
      }, 
      {
        "UID": "21P02", 
        "abstract": "Set classification is the task of predicting a single label from a set comprising multiple instances. The examples we consider are pathology slides represented by sets of patches and medical text represented by sets of word embeddings. State of the art methods, such as the transformers, typically use attention mechanisms to learn representations of set-data by modeling interactions between instances of the set. These methods, however, have complex heuristic architectures comprising multiple heads and layers. The complexity of attention architectures hampers their training when only a small number of labeled sets is available, as is often the case in medical applications. To address this problem, we present a kernel-based representation learning framework that associates between learning affinity kernels to learning representations from attention architectures. We show that learning a combination of the sum and the product of kernels is equivalent to learning representations from multi-head multi-layer attention architectures. From our framework, we devise a simplified attention architecture which we term \\emph{affinitention} (affinity-attention) nets. We demonstrate the application of affinitention nets to the classification of Set-Cifar10 dataset, thyroid malignancy prediction from pathology slides, as well as patient text message-triage. We show that affinitention nets provide competitive results compared to heuristic attention architectures and outperform other competing methods.", 
        "authors": "David Dov, Serge Assaad, Shijing Si, and Rui Wang (Duke University) | Hongteng Xu (Renmin University of China) | Shahar Ziv Kovalsky (UNC at Chapel Hill) | Jonathan Bell and Danielle Elliott Range (Duke University Hospital) | Jonathan Cohen (Kaplan Medical Center) | Ricardo Henao and Lawrence Carin (Duke University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451856", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954723", 
        "title": "Affinitention Nets: Kernel Perspective on Attention Architectures for Set Classification with Applications to Medical Text and Images"
      }, 
      {
        "UID": "21P03", 
        "abstract": "Machine Learning, and in particular Federated Machine Learning, opens new perspectives in terms of medical research and patient care. Although Federated Machine Learning improves over centralized Machine Learning in terms of privacy, it does not provide provable privacy guarantees. Furthermore, Federated Machine Learning is quite expensive in term of bandwidth consumption as it requires participant nodes to regularly exchange large updates. This paper proposes a bandwidth-efficient privacy-preserving Federated Learning that provides theoretical privacy guarantees based on Differential Privacy. We experimentally evaluate our proposal for in-hospital mortality prediction using a real dataset, containing Electronic Health Records of about one million patients. Our results suggest that strong and provable patient-level privacy can be enforced at the expense of only a moderate loss of prediction accuracy.", 
        "authors": "Raouf Kerkouche (Privatics team, Univ. Grenoble Alpes, Inria, 38000 Grenoble, France) | Gergely \u00c1cs (Crysys Lab, BME-HIT) | Claude Castelluccia (Privatics team, Univ. Grenoble Alpes, Inria, 38000 Grenoble, France) | Pierre Genev\u00e8s (Tyrex team Univ. Grenoble Alpes, CNRS, Inria, Grenoble INP, LIG 38000 Grenoble, France)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451859", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954724", 
        "title": "Privacy-Preserving and Bandwidth-Efficient Federated Learning: An Application to In-Hospital Mortality Prediction"
      }, 
      {
        "UID": "21P04", 
        "abstract": "Recurrent Neural Networks (RNNs) are often used for sequential modeling of adverse outcomes in electronic health records (EHRs) due to their ability to encode past clinical states. These deep, recurrent architectures have displayed increased performance compared to other modeling approaches in a number of tasks, fueling the interest in deploying deep models in clinical settings. One of the key elements in ensuring safe model deployment and building user trust is model explainability. Testing with Concept Activation Vectors (TCAV) has recently been introduced as a way of providing human-understandable explanations by comparing high-level concepts to the network's gradients. While the technique has shown promising results in real-world imaging applications, it has not been applied to structured temporal inputs. To enable an application of TCAV to sequential predictions in the EHR, we propose an extension of the method to time series data. We evaluate the proposed approach on an open EHR benchmark from the intensive care unit, as well as synthetic data where we are able to better isolate individual effects.", 
        "authors": "Diana Mincu (Google Research) | Eric Loreaux (Google Health) | Shaobo Hou (DeepMind) | Sebastien Baur, Ivan Protsyuk, and Martin G Seneviratne (Google Health) | Anne Mottram and Nenad Tomasev (DeepMind) | Alan Karthikesalingam (Google Health) | Jessica Schrouff (Google Research)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451858", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954725", 
        "title": "Concept-based Model Explanations for Electronic Health Records"
      }, 
      {
        "UID": "21P05", 
        "abstract": "Sharing data is critical to generate large data sets required for the training of machine learning models. Trustworthy machine learning requires incentives, guarantees of data quality, and information privacy. Applying recent advancements in data valuation methods for machine learning can help to enable these. In this work, we analyze the suitability of three different data valuation methods for medical image classification tasks, specifically pleural effusion, on an extensive data set of chest x-ray scans. Our results reveal that a heuristic for calculating the Shapley valuation scheme based on a k-nearest neighbor classifier can successfully value large quantities of data instances. We also demonstrate possible applications for incentivizing data sharing, the efficient detection of mislabeled data, and summarizing data sets to exclude private information. Thereby, this work contributes to developing modern data infrastructures for trustworthy machine learning in health care.", 
        "authors": "Konstantin D Pandl, Fabian Feiland, Scott Thiebes, and Ali Sunyaev (Karlsruhe Institute of Technology)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451861", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954726", 
        "title": "Trustworthy Machine Learning for Health Care: Scalable Data Valuation with the Shapley Value"
      }, 
      {
        "UID": "21P06", 
        "abstract": "The pressure of ever-increasing patient demand and budget restrictions make hospital bed management a daily challenge for clinical staff. Most critical is the efficient allocation of resource-heavy Intensive Care Unit (ICU) beds to the patients who need life support. Central to solving this problem is knowing for how long the current set of ICU patients are likely to stay in the unit. In this work, we propose a new deep learning model based on the combination of temporal convolution and pointwise (1x1) convolution, to solve the length of stay prediction task on the eICU and MIMIC-IV critical care datasets. The model - which we refer to as Temporal Pointwise Convolution (TPC) - is specifically designed to mitigate common challenges with Electronic Health Records, such as skewness, irregular sampling and missing data. In doing so, we have achieved significant performance benefits of 18-68% (metric and dataset dependent) over the commonly used Long-Short Term Memory (LSTM) network, and the multi-head self-attention network known as the Transformer. By adding mortality prediction as a side-task, we can improve performance further still, resulting in a mean absolute deviation of 1.55 days (eICU) and 2.28 days (MIMIC-IV) on predicting remaining length of stay.", 
        "authors": "Emma Rocheteau and Pietro Li\u00f2 (University of Cambridge) | Stephanie Hyland (Microsoft Research)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451860", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954727", 
        "title": "Temporal Pointwise Convolutional Networks for Length of Stay Prediction in the Intensive Care Unit"
      }, 
      {
        "UID": "21P07", 
        "abstract": "Wearable devices such as smartwatches are becoming increasingly popular tools for objectively monitoring physical activity in free-living conditions. To date, research has primarily focused on the purely supervised task of human activity recognition, demonstrating limited success in inferring high-level health outcomes from low-level signals. Here, we present a novel _self-supervised_ representation learning method using activity and heart rate (HR) signals without semantic labels. With a deep neural network, we set HR responses as the _supervisory signal_ for the activity data, leveraging their underlying physiological relationship. In addition, we propose a custom quantile loss function that accounts for the long-tailed HR distribution present in the general population. We evaluate our model in the largest free-living combined-sensing dataset (comprising >280k hours of wrist accelerometer & wearable ECG data). Our contributions are two-fold: i) the pre-training task creates a model that can accurately forecast HR based only on cheap activity sensors, and ii) we leverage the information captured through this task by proposing a simple method to aggregate the learnt latent representations (embeddings) from the window-level to user-level. Notably, we show that the embeddings can generalize in various downstream tasks through transfer learning with linear classifiers, capturing physiologically meaningful, personalized information. For instance, they can be used to predict variables associated with individuals' health, fitness and demographic characteristics (AUC >70), outperforming unsupervised autoencoders and common bio-markers. Overall, we propose the first multimodal self-supervised method for behavioral and physiological data with implications for large-scale health and lifestyle monitoring. <br /><br /><strong>Code:</strong> <a href='https://github.com/sdimi/Step2heart' target='_blank' rel='noopener'>https://github.com/sdimi/Step2heart</a>", 
        "authors": "Dimitris Spathis, Ignacio Pozuelo, Soren Brage, Nicholas J. Wareham, and Cecilia Mascolo (University of Cambridge)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451863", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954728", 
        "title": "Self-supervised Transfer Learning of Physiological Representations from Free-living Wearable Data"
      }, 
      {
        "UID": "21P08", 
        "abstract": "In several crucial applications, domain knowledge is encoded by a system of ordinary differential equations (ODE), often stemming from underlying physical and biological processes. A motivating example is intensive care unit patients: the dynamics of vital physiological functions, such as the cardiovascular system with its associated variables (heart rate, cardiac contractility and output and vascular resistance) can be approximately described by a known system of ODEs. Typically, some of the ODE variables are directly observed (heart rate and blood pressure for example) while some are unobserved (cardiac contractility, output and vascular resistance), and in addition many other variables are observed but not modeled by the ODE, for example body temperature. Importantly, the unobserved ODE variables are ``known-unknowns'': We know they exist and their functional dynamics, but cannot measure them directly, nor do we know the function tying them to all observed measurements. As is often the case in medicine, and specifically the cardiovascular system, estimating these known-unknowns is highly valuable and they serve as targets for therapeutic manipulations. Under this scenario we wish to learn the parameters of the ODE generating each observed time-series, and extrapolate the future of the ODE variables and the observations. We address this task with a variational autoencoder incorporating the known ODE function, called GOKU-net for Generative ODE modeling with Known Unknowns. We first validate our method on videos of single and double pendulums with unknown length or mass; we then apply it to a model of the cardiovascular system. We show that modeling the known-unknowns allows us to successfully discover clinically meaningful unobserved system parameters, leads to much better extrapolation, and enables learning using much smaller training sets.", 
        "authors": "Ori Linial and Neta Ravid (Technion) | Danny Eytan (Technion, Rambam) | Uri Shalit (Technion)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451866", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954729", 
        "title": "Generative ODE Modeling with Known Unknowns"
      }, 
      {
        "UID": "21P09", 
        "abstract": "The impact of machine learning models on healthcare will depend on the degree of trust that healthcare professionals place in the predictions made by these models. In this paper, we present a method to provide people with clinical expertise with domain-relevant evidence about why a prediction should be trusted. We first design a probabilistic model that relates meaningful latent concepts to prediction targets and observed data. Inference of latent variables in this model corresponds to both making a prediction $\\textit{and}$ providing supporting evidence for that prediction. We present a two-step process to efficiently approximate inference: (i) estimating model parameters using variational learning, and (ii) approximating $\\textit{maximum a posteriori}$ estimation of latent variables in the model using a neural network trained with an objective derived from the probabilistic model. We demonstrate the method on the task of predicting mortality risk for cardiovascular patients. Specifically, using electrocardiogram and tabular data as input, we show that our approach provides appropriate domain-relevant supporting evidence for accurate predictions.", 
        "authors": "Aniruddh Raghu and John Guttag (Massachusetts Institute of Technology) | Katherine Young (Harvard Medical School) | Eugene Pomerantsev (Massachusetts General Hospital) | Adrian V. Dalca (Harvard Medical School & MIT) | Collin M. Stultz (Massachusetts Institute of Technology)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451869", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954730", 
        "title": "Learning to Predict with Supporting Evidence: Applications to Clinical Risk Prediction"
      }, 
      {
        "UID": "21P10", 
        "abstract": "Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24).", 
        "authors": "Saahil Jain and Akshay Smit (Stanford University) | Steven QH Truong, Chanh DT Nguyen, and Minh-Thanh Huynh (VinBrain) | Mudit Jain (unaffiliated) | Victoria A. Young, Andrew Y. Ng, Matthew P. Lungren, and Pranav Rajpurkar (Stanford University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451862", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954731", 
        "title": "VisualCheXbert: Addressing the Discrepancy Between Radiology Report Labels and Image Labels"
      }, 
      {
        "UID": "21P11", 
        "abstract": "Deep learning methods for chest X-ray interpretation typically rely on pretrained models developed for ImageNet. This paradigm assumes that better ImageNet architectures perform better on chest X-ray tasks and that ImageNet-pretrained weights provide a performance boost over random initialization. In this work, we compare the transfer performance and parameter efficiency of 16 popular convolutional architectures on a large chest X-ray dataset (CheXpert) to investigate these assumptions. First, we find no relationship between ImageNet performance and CheXpert performance for both models without pretraining and models with pretraining. Second, we find that, for models without pretraining, the choice of model family influences performance more than size within a family for medical imaging tasks. Third, we observe that ImageNet pretraining yields a statistically significant boost in performance across architectures, with a higher boost for smaller architectures. Fourth, we examine whether ImageNet architectures are unnecessarily large for CheXpert by truncating final blocks from pretrained models, and find that we can make models 3.25x more parameter-efficient on average without a statistically significant drop in performance. Our work contributes new experimental evidence about the relation of ImageNet to chest x-ray interpretation performance.", 
        "authors": "Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y. Ng, and Pranav Rajpurkar (Stanford University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451867", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954732", 
        "title": "CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation"
      }, 
      {
        "UID": "21P12", 
        "abstract": "Recent advances in training deep learning models have demonstrated the potential to provide accurate chest X-ray interpretation and increase access to radiology expertise. However, poor generalization due to data distribution shifts in clinical settings is a key barrier to implementation. In this study, we measured the diagnostic performance for 8 different chest X-ray models when applied to (1) smartphone photos of chest X-rays and (2) external datasets without any finetuning. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to test datasets without further tuning. We found that (1) on photos of chest X-rays, all 8 models experienced a statistically significant drop in task performance, but only 3 performed significantly worse than radiologists on average, and (2) on the external set, none of the models performed statistically significantly worse than radiologists, and five models performed statistically significantly better than radiologists. Our results demonstrate that some chest X-ray models, under clinically relevant distribution shifts, were comparable to radiologists while other models were not. Future work should investigate aspects of model training procedures and dataset collection that influence generalization in the presence of data distribution shifts.", 
        "authors": "Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Andrew Y. Ng, and Matthew P. Lungren (Stanford University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451876", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954733", 
        "title": "CheXternal: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays and External Clinical Settings"
      }, 
      {
        "UID": "21P13", 
        "abstract": "Balanced representation learning methods have been applied successfully to counterfactual inference from observational data. However, approaches that account for survival outcomes are relatively limited. Survival data are frequently encountered across diverse medical applications, \\textit{i.e.}, drug development, risk profiling, and clinical trials, and such data are also relevant in fields like manufacturing (\\textit{e.g.}, for equipment monitoring). When the outcome of interest is a time-to-event, special precautions for handling censored events need to be taken, as ignoring censored outcomes may lead to biased estimates. We propose a theoretically grounded unified framework for counterfactual inference applicable to survival outcomes. Further, we formulate a nonparametric hazard ratio metric for evaluating average and individualized treatment effects. Experimental results on real-world and semi-synthetic datasets, the latter of which we introduce, demonstrate that the proposed approach significantly outperforms competitive alternatives in both survival-outcome prediction and treatment-effect estimation.", 
        "authors": "Paidamoyo Chapfuwa, Serge Assaad, Shuxi Zeng, Michael Pencina, Lawrence Carin, and Ricardo Henao (Duke University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451875", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954734", 
        "title": "Enabling Counterfactual Survival Analysis with Balanced Representations"
      }, 
      {
        "UID": "21P14", 
        "abstract": "Generating a novel and optimized molecule with desired chemical properties is an essential part of the drug discovery process. Failure to meet one of the required properties can frequently lead to failure in a clinical test which is costly. In addition, optimizing these multiple properties is a challenging task because the optimization of one property is prone to changing other properties. In this paper, we pose this multi-property optimization problem as a sequence translation process and propose a new optimized molecule generator model based on the Transformer with two constraint networks: property prediction and similarity prediction. We further improve the model by incorporating score predictions from these constraint networks in a modified beam search algorithm. The experiments demonstrate that our proposed model outperforms state-of-the-art models by a significant margin for optimizing multiple properties simultaneously.", 
        "authors": "Bonggun Shin and Sungsoo Park (Deargen Inc.) | JinYeong Bak (SungKyunKwan University) | Joyce C. Ho (Emory University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451879", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954735", 
        "title": "Controlled Molecule Generator for Optimizing Multiple Chemical Properties"
      }, 
      {
        "UID": "21P15", 
        "abstract": "There are large individual differences in physiological processes, making designing personalized health sensing algorithms challenging. Existing machine learning systems struggle to generalize well to unseen subjects or contexts and can often contain problematic biases. Video-based physiological measurement is not an exception. Therefore, learning personalized or customized models from a small number of unlabeled samples is very attractive as it would allow fast calibrations to improve generalization and help correct biases. In this paper, we present a novel meta-learning approach called MetaPhys for personalized video-based cardiac measurement. Our method uses only 18-seconds of video for customization and works effectively in both supervised and unsupervised manners. We evaluate our proposed approach on two benchmark datasets and demonstrate superior performance in cross-dataset evaluation with substantial reductions (42% to 44%) in errors compared with state-of-the-art approaches. We have also demonstrated our proposed method significantly helps reduce the bias in skin type.", 
        "authors": "Xin Liu and Ziheng Jiang (University of Washington) | Josh Fromm (OctoML) | Xuhai Xu and Shwetak Patel (University of Washington) | Daniel McDuff (Microsoft Research)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451870", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954736", 
        "title": "MetaPhys: Few-Shot Adaptation for Non-Contact Physiological Measurement"
      }, 
      {
        "UID": "21P16", 
        "abstract": "Machine learning algorithms in healthcare have the potential to continually learn from real-world data generated during healthcare delivery and adapt to dataset shifts. As such, regulatory bodies like the US FDA have begun discussions on how to autonomously approve modifications to algorithms. Current proposals evaluate algorithmic modifications via hypothesis testing. However, these methods are only able to define and control the online error rate if the data is stationary over time, which is unlikely to hold in practice. In this manuscript, we investigate designing approval policies for modifications to ML algorithms in the presence of distributional shifts. Our key observation is that the approval policy that is most efficient at identifying and approving beneficial modifications varies across different problem settings. So rather than selecting fixed approval policy a priori, we propose learning the best approval policy by searching over a family of approval strategies. We define a family of strategies that range in their level of optimism when approving modifications. This family includes the pessimistic strategy that, in fact, rescinds approval, which is necessary when no version of the ML algorithm performs well. We use the exponentially weighted averaging forecaster (EWAF) to learn the most appropriate strategy and derive tighter regret bounds assuming the distributional shifts are bounded. In simulation studies and empirical analyses, we find that wrapping approval strategies within EWAF algorithm is a simple yet effective strategy that can help protect against distributional shifts without significantly slowing down approval of beneficial modifications.", 
        "authors": "Jean Feng (University of California, San Francisco)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451864", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954737", 
        "title": "Learning to Safely Approve Updates to Machine Learning Algorithms"
      }, 
      {
        "UID": "21P17", 
        "abstract": "The black-box nature of the deep networks makes the explanation for \"why\" they make certain predictions extremely challenging. Saliency maps are one of the most widely-used local explanation tools to alleviate this problem. One of the primary approaches for generating saliency maps is by optimizing a mask over the input dimensions so that the output of the network is influenced the most by the masking. However, prior work only studies such influence by removing evidence from the input. In this paper, we present iGOS++, a framework to generate saliency maps that are optimized for altering the output of the black-box system by either removing or preserving only a small fraction of the input. Additionally, we propose to add a bilateral total variation term to the optimization that improves the continuity of the saliency map especially under high resolution and with thin object parts. The evaluation results from comparing iGOS++ against state-of-the-art saliency map methods show significant improvement in locating salient regions that are directly interpretable by humans. We utilized iGOS++ in the task of classifying COVID-19 cases from x-ray images and discovered that sometimes the CNN network is overfitted to the characters printed on the x-ray images when performing classification. Fixing this issue by data cleansing significantly improved the precision and recall of the classifier.", 
        "authors": "Saeed Khorram, Tyler Lawson, and Fuxin Li (Oregon State University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451865", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954738", 
        "title": "iGOS++: Integrated Gradient Optimized Saliency by Bilateral Perturbations"
      }, 
      {
        "UID": "21P18", 
        "abstract": "Despite the large number of patients in Electronic Health Records (EHRs), the subset of usable data for modeling outcomes of specific phenotypes are often imbalanced and of modest size. This can be attributed to the uneven coverage of medical concepts in EHRs. We propose OMTL, an Ontology-driven Multi-Task Learning framework, that is designed to overcome such data limitations.The key contribution of our work is the effective use of knowledge from a predefined well-established medical relationship graph (ontology) to construct a novel deep learning network architecture that mirrors this ontology. This enables common representations to be shared across related phenotypes, and was found to improve the learning performance. The proposed OMTL naturally allows for multi-task learning of different phenotypes on distinct predictive tasks. These phenotypes are tied together by their semantic relationship according to the external medical ontology. Using the publicly available MIMIC-III database, we evaluate OMTL and demonstrate its efficacy on several real patient outcome predictions over state-of-the-art multi-task learning schemes. The results of evaluating the proposed approach on six experiments show improvement in the area under ROC curve by 9\\% and by 8\\% in the area under precision-recall curve.", 
        "authors": "Mohamed Ghalwash, Zijun Yao, Prithwish Chakraborty, james Codella, and Daby Sow (IBM Research)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451881", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954748", 
        "title": "Phenotypical Ontology Driven Framework for Multi-Task Learning"
      }, 
      {
        "UID": "21P19", 
        "abstract": "A single gene can encode for different protein versions through a process called alternative splicing. Since proteins play major roles in cellular functions, aberrant splicing profiles can result in a variety of diseases, including cancers. Alternative splicing is determined by the gene's primary sequence and other regulatory factors such as RNA-binding protein levels. With these as input, we formulate the prediction of RNA splicing as a regression task and build a new training dataset (CAPD) to benchmark learned models. We propose discrete compositional energy network (DCEN) which leverages the hierarchical relationships between splice sites, junctions and transcripts to approach this task. In the case of alternative splicing prediction, DCEN models mRNA transcript probabilities through its constituent splice junctions' energy values. These transcript probabilities are subsequently mapped to relative abundance values of key nucleotides and trained with ground-truth experimental measurements. Through our experiments on CAPD, we show that DCEN outperforms baselines and ablation variants.", 
        "authors": "Alvin Chan, Anna Korsakova, Yew-Soon Ong, Fernaldo Richtia Winnerdy, Kah Wai Lim, and Anh Tuan Phan (Nanyang Technological University)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451857", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954739", 
        "title": "RNA Alternative Splicing Prediction with Discrete Compositional Energy Network"
      }, 
      {
        "UID": "21P20", 
        "abstract": "Colorectal cancer recurrence is a major clinical problem - around 30-40% of patients who are treated with curative intent surgery will experience cancer relapse. Proactive prognostication is critical for early detection and treatment of recurrence. However, the common clinical approach to monitoring recurrence through testing for carcinoembryonic antigen (CEA) does not possess a strong prognostic performance. In our paper, we study a series of machine and deep learning architectures that exploit heterogeneous healthcare data to predict colorectal cancer recurrence. In particular, we demonstrate three different approaches to extract and integrate features from multiple modalities including longitudinal as well as tabular clinical data. Our best model employs a hybrid architecture that takes in multi-modal inputs and comprises: 1) a Transformer model carefully modified to extract high-quality features from time-series data, and 2) a Multi-Layered Perceptron (MLP) that learns tabular data features, followed by feature integration and classification for prediction of recurrence. It achieves an AUROC score of 0.95, as well as precision, sensitivity and specificity scores of 0.83, 0.80 and 0.96 respectively, surpassing the performance of all-known published results based on CEA, as well as most commercially available diagnostic assays. Our results could lead to better post-operative management and follow-up of colorectal cancer patients.", 
        "authors": "Danliang Ho (National University of Singapore) | Iain Bee Huat Tan (National Cancer Center Singapore) | Mehul Motani (National University of Singapore)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451868", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954740", 
        "title": "Predictive Models for Colorectal Cancer Recurrence Using Multi-modal Healthcare Data"
      }, 
      {
        "UID": "21P21", 
        "abstract": "Melanoma is the most common form of cancer in the world. Early diagnosis of the disease and an accurate estimation of its size and shape are crucial in preventing its spread to other body parts. Manual segmentation of these lesions by a radiologist however is time consuming and error-prone. It is clinically desirable to have an automatic tool to detect malignant skin lesions from dermoscopic skin images. We propose a novel end-to-end convolution neural network(CNN) for a precise and robust skin lesion localization and segmentation. The proposed network has 3 sub-encoders branching out from the main encoder. The 3 sub-encoders are inspired from Coordinate Convolution, Hourglass, and Octave Convolutional blocks: each sub-encoder summarizes different patterns and yet collectively aims to achieve a precise segmentation. We trained our segmentation model just on the ISIC 2018 dataset. To demonstrate the generalizability of our model, we evaluated our model on the ISIC 2018 and unseen datasets including ISIC 2017 and PH$^2$. Our approach showed an average 5\\% improvement in performance over different datasets while having less than half of the number of parameters when compared to other state-of-the-art segmentation models.", 
        "authors": "shreshth saini (indian institute of technology jodhpur) | Jeon Young Seok and Mengling Feng (Saw Swee Hock School of PublicHealth, National University HealthSystem, National University ofSingapore)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451873", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954741", 
        "title": "B-SegNet : Branched-SegMentor Network For Skin Lesion Segmentation"
      }, 
      {
        "UID": "21P22", 
        "abstract": "In medicine, comorbidities refer to the presence of multiple, co-occurring diseases. Due to their co-occurring nature, the course of one comorbidity is often highly dependent on the course of the other disease and, hence, treatments can have significant spill-over effects. Despite the prevalence of comorbidities among patients, a comprehensive statistical framework for modeling the longitudinal dynamics of comorbidities is missing. In this paper, we propose a probabilistic model for analyzing comorbidity dynamics over time in patients. Specifically, we develop a coupled hidden Markov model with a personalized, non-homogeneous transition mechanism, named Comorbidity-HMM. The specification of our Comorbidity-HMM is informed by clinical research: (1) It accounts for different disease states (i. e., acute, stable) in the disease progression by introducing latent states that are of clinical meaning. (2) It models a coupling among the trajectories from comorbidities to capture co-evolution dynamics. (3) It considers between-patient heterogeneity (e. g., risk factors, treatments) in the transition mechanism. Based on our model, we define a spill-over effect that measures the indirect effect of treatments on patient trajectories through coupling (i. e., through comorbidity co-evolution). We evaluated our proposed Comorbidity-HMM based on 675 health trajectories where we investigate the joint progression of diabetes mellitus and chronic liver disease. Compared to alternative models without coupling, we find that our Comorbidity-HMM achieves a superior fit. Further, we quantify the spill-over effect, that is, to what extent diabetes treatments are associated with a change in the chronic liver disease from an acute to a stable disease state. To this end, our model is of direct relevance for both treatment planning and clinical research in the context of comorbidities.", 
        "authors": "Basil Maag, Stefan Feuerriegel, and Mathias Kraus (ETH Zurich) | Maytal Saar-Tsechansky (University of Texas at Austin) | Thomas Zueger (1) Inselspital, Bern, University Hospital, University of Bern 2) ETH Zurich)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451871", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954742", 
        "title": "Modeling Longitudinal Dynamics of Comorbidities"
      }, 
      {
        "UID": "21P23", 
        "abstract": "Generating interpretable visualizations of multivariate time series in the intensive care unit is of great practical importance. Clinicians seek to condense complex clinical observations into intuitively understandable critical illness patterns, like failures of different organ systems. They would greatly benefit from a low-dimensional representation in which the trajectories of the patients' pathology become apparent and relevant health features are highlighted. To this end, we propose to use the latent topological structure of Self-Organizing Maps (SOMs) to achieve an interpretable latent representation of ICU time series and combine it with recent advances in deep clustering. Specifically, we (a) present a novel way to fit SOMs with probabilistic cluster assignments (PSOM), (b) propose a new deep architecture for probabilistic clustering (DPSOM) using a VAE, and (c) extend our architecture to cluster and forecast clinical states in time series (T-DPSOM). We show that our model achieves superior clustering performance compared to state-of-the-art SOM-based clustering methods while maintaining the favorable visualization properties of SOMs. On the eICU data-set, we demonstrate that T-DPSOM provides interpretable visualizations of patient state trajectories and uncertainty estimation. We show that our method rediscovers well-known clinical patient characteristics, such as a dynamic variant of the Acute Physiology And Chronic Health Evaluation (APACHE) score. Moreover, we illustrate how it can disentangle individual organ dysfunctions on disjoint regions of the two-dimensional SOM map.", 
        "authors": "Laura Manduchi, Matthias H\u00fcser, Martin Faltys, Julia Vogt, Gunnar R\u00e4tsch, and Vincent Fortuin (ETH Z\u00fcrich)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451872", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954743", 
        "title": "T-DPSOM - An Interpretable Clustering Method for Unsupervised Learning of Patient Health States"
      }, 
      {
        "UID": "21P24", 
        "abstract": "Wearable technology opens opportunities to reduce sedentary behavior; however, commercially available devices do not provide tailored coaching strategies. Just-In-Time Adaptive Interventions (JITAI) provide such a framework; however most JITAI are conceptual to date. We conduct a study to evaluate just-in-time nudges in free-living conditions in terms of receptiveness and nudge impact. We first quantify baseline behavioral patterns in context using features such as location and step count, and assess differences in individual responses. We show there is a strong inverse relationship between average daily step counts and time spent being sedentary indicating that steps are steadily taken throughout the day, rather than in large bursts. Interestingly, the effect of nudges delivered at the workplace is larger in terms of step count than those delivered at home. We develop Random Forest models to learn nudge receptiveness using both individualized and contextualized data. We show that step count is the least important identifier in nudge receptiveness, while location is the most important. Furthermore, we compare the developed models with a commercially available smart coach using post-hoc analysis. The results show that using the contextualized and individualized information significantly outperforms non-JITAI approaches to determine nudge receptiveness.", 
        "authors": "Matthew Saponaro, Ajith Vemuri, Greg Dominick, and Keith Decker (University of Delaware)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451874", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954744", 
        "title": "Contextualization and Individualization for Just-in-Time Adaptive Interventions to Reduce Sedentary Behavior"
      }, 
      {
        "UID": "21P25", 
        "abstract": "Pre-training (PT) has been used successfully in many areas of machine learning. One area where PT would be extremely impactful is over electronic health record (EHR) data. Successful PT strategies on this modality could improve model performance in data-scarce contexts such as modeling for rare diseases or allowing smaller hospitals to benefit from data from larger health systems. While many PT strategies have been explored in other domains, much less exploration has occurred for EHR data. One reason this may be is the lack of standardized benchmarks suitable for developing and testing PT algorithms. In this work, we establish a PT benchmark dataset for EHR timeseries data, establishing cohorts, a diverse set of fine-tuning tasks, and PT-focused evaluation regimes across two public EHR datasets: MIMIC-III and eICU. This benchmark fills an essential hole in the field by enabling a robust manner of iterating on PT strategies for this modality. To show the value of this benchmark and provide baselines for further research, we also profile two simple PT algorithms: a self-supervised, masked imputation system and a weakly-supervised, multi-task system. We find that PT strategies (in particular weakly-supervised PT methods) can offer significant gains over traditional learning in few-shot settings, especially on tasks with strong class imbalance. Our full benchmark and code are publicly available at <a href='https://github.com/mmcdermott/comprehensive_MTL_EHR' target='_blank' rel='noopener'>https://github.com/mmcdermott/comprehensive_MTL_EHR</a>.", 
        "authors": "Matthew McDermott (Massachusetts Institute of Technology) | Bret Nestor (University of Toronto) | Evan Kim (Massachusetts Institute of Technology) | Wancong Zhang (New York University) | Anna Goldenberg (Hospital for Sick Children, University of Toronto, Vector Institute) | Peter Szolovits (MIT) | Marzyeh Ghassemi (University of Toronto | Vector Institute for Artificial Intelligence)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451877", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954745", 
        "title": "A Comprehensive EHR Timeseries Pre-training Benchmark"
      }, 
      {
        "UID": "21P26", 
        "abstract": "Clinical machine learning models have been found to significantly degrade in performance on hospitals or regions not seen during training. Recent developments in domain generalization offer a promising solution to this problem, by creating models that learn invariances which hold across environments. In this work, we benchmark the performance of eight domain generalization methods on clinical time series and medical imaging data. We introduce a framework to induce practical confounding and sampling bias to stress-test these methods over existing non-healthcare benchmarks. We find, consistent with prior work, that current domain generalization methods do not achieve significant gains in out-of-distribution performance over empirical risk minimization on real-world medical imaging data. However, we do find a subset of realistic confounding scenarios where significant performance gains are observed. We characterize these scenarios in detail, and recommend best practices for domain generalization in the clinical setting.", 
        "authors": "Haoran Zhang (University of Toronto | Vector Institute) | Natalie Dullerud (University of Toronto, Vector Institute) | Laleh Seyyed-Kalantari (University of Toronto) | Quaid Morris (Memorial Sloan Kettering Cancer Center) | Shalmali Joshi (Harvard University) | Marzyeh Ghassemi (University of Toronto | Vector Institute for Artificial Intelligence)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451878", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954746", 
        "title": "An Empirical Framework for Domain Generalization In Clinical Settings"
      }, 
      {
        "UID": "21P27", 
        "abstract": "Early detection of influenza-like symptoms can prevent widespread flu viruses and enable timely treatments, particularly in the post-pandemic era. Mobile sensing leverages an increasingly diverse set of embedded sensors to capture fine-grained information of human behaviors and ambient contexts and can serve as a promising solution for influenza-like symptom recognition. Traditionally, handcrafted and high level features of mobile sensing data are extracted by using handcrafted feature engineering and Convolutional/Recurrent Neural Network respectively. However, in this work, we use graph representation to encode the dynamics of state transitions and internal dependencies in human behaviors, apply graph embeddings to automatically extract the topological and spatial features from graph input and propose an end-to-end Graph Neural Network model with multi-channel mobile sensing input for influenza-like symptom recognition based on people's daily mobility, social interactions, and physical activities. Using data generated from 448 participants, We show that Graph Neural Networks (GNN) with GraphSAGE convolutional layers significantly outperform baseline models with handcrafted features. Furthermore, we use GNN interpretability method to generate insight (important node, graph structure) for the symptom recognition. To the best of our knowledge, this is the first work that applies graph representation and graph neural network on mobile sensing data for graph-based human behaviors modeling.", 
        "authors": "Guimin Dong, Lihua Cai, Debajyoti Datta, Shashwat Kumar, Laura E. Barnes, and Mehdi Boukhechba (University of Virginia)", 
        "doi_link": "https://doi.org/10.1145/3450439.3451880", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954747", 
        "title": "Influenza-like Symptom Recognition using Mobile Sensing and Graph Neural Networks"
      }
    ], 
    "speakers": [
      {
        "UID": "21K01", 
        "abstract": "Until today, all the available therapeutics are designed by human experts, with no help from AI tools. This reliance on human knowledge and dependence on large-scale experimentations result in prohibitive development cost and high failure rate. Recent developments in machine learning algorithms for molecular modeling aim to transform this field. In my talk, I will present state-of-the-art approaches for property prediction and de-novo molecular generation, describing their use in drug design. In addition, I will highlight unsolved algorithmic questions in this field, including confidence estimation, pretraining, and deficiencies in learned molecular representations.", 
        "bio": "Regina Barzilay is a professor in the Department of Electrical Engineering and Computer Science and a member of the Computer Science and Artificial Intelligence Laboratory at the Massachusetts Institute of Technology. She is an AI faculty lead for Jameel Clinic, an MIT center for Machine Learning in Health at MIT. Her research interests are in natural language processing, applications of deep learning to chemistry and oncology. She is a recipient of various awards including the NSF Career Award, the MIT Technology Review TR-35 Award, Microsoft Faculty Fellowship and several Best Paper Awards at NAACL and ACL. In 2017, she received a MacArthur fellowship, an ACL fellowship and an AAAI fellowship. In 2020, she was awarded AAAI Squirrel Award for Artificial Intelligence for the Benefit of Humanity. She received her Ph.D. in Computer Science from Columbia University, and spent a year as a postdoc at Cornell University. Regina received her undergraduate from Ben Gurion University of the Negev, Israel.", 
        "image": "static/images/speakers/r-barzilay.jpg", 
        "institution": "MIT Computer Science & Artificial Intelligence Lab", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954711", 
        "speaker": "Regina Barzilay", 
        "title": "AI for Drug Discovery: Challenges and Opportunities", 
        "website": "https://www.regina.csail.mit.edu"
      }, 
      {
        "UID": "21K02", 
        "abstract": "Improved healthcare delivery and patient outcomes are the ultimate goals of many AI applications in healthcare. However, relatively few machine learning models have been translated to clinical practice so far and among those even fewer have undergone a randomized control trial (RCT) to assess their impact. This talk will highlight aspects of the clinical translational process, beyond retrospective modeling, that impact design, development, validation, and regulation of machine learning models in healthcare. In particular, this talk focuses on our recent study of predicting favorable outcomes in hospitalized COVID-19 patients. The resulting model, which was deployed and prospectively validated at NYU Langone, underwent an RCT, and was eventually shared with other institutions. I will discuss challenges around integrating our model in the EHR system and their implications, the efficacy and safety results of our RCT, and practical insights about sharing models across clinics. We will end the talk by reviewing results of a survey of over 195 clinical users who interacted with this model, summarizing when and how the model was most helpful.", 
        "bio": "Narges Razavian is an assistant professor at NYU Langone Health, Center for Healthcare Innovation and Delivery Sciences, and Predictive Analytics Unit. Her lab focuses on various applications of Machine Learning and AI for medicine with a clinical translation outlook, and they work with Medical Images, Clinical Notes, and Electronic Health Records. Before NYU Langone, she was a postdoc at CILVR lab at NYU Courant CS department. She received her PhD at CMU Computational Biology group.", 
        "image": "static/images/speakers/n-razavian.jpg", 
        "institution": "New York University Langone Medical Center", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954712", 
        "speaker": "Narges Razavian", 
        "title": "Machine Learning in Healthcare: From Modeling to Clinical Impact", 
        "website": "http://razavian.net/"
      }, 
      {
        "UID": "21K03", 
        "abstract": "In early March 2020, Mark joined an interdisciplinary team to launch the Pandemic Response Network. Over the subsequent months, he helped build and launch programs to support health workers, university students and staff, small businesses, K-12 public schools, and historically marginalized communities through the COVID-19 pandemic. With a strong background in design and implementation of high-tech health innovations, Mark worked alongside public health practitioners and community leaders to repeatedly execute the last mile implementation of critical COVID-19 programs, including symptom monitoring in the workplace, rapid antigen testing in schools, and pop-up vaccination events in churches. The portfolio of programs rapidly shifted health care capabilities and expertise out of hospitals and clinics into community settings that were poorly supported by existing public health infrastructure. The experience forced Mark and his team to approach technology design with a new set of assumptions and led to the development of completely novel data streams and technology systems. In his talk, Mark distills insights and learnings from the front lines of the COVID-19 response and highlights important implications and opportunities for the field of machine learning and artificial intelligence in health care.", 
        "bio": "Mark Sendak, MD, MPP is the Population Health & Data Science Lead at the Duke Institute for Health Innovation (DIHI), where he leads interdisciplinary teams of data scientists, clinicians, and machine learning experts to build technologies that solve real clinical problems. He has built tools to support Duke Health's Accountable Care Organization, COVID-19 Pandemic Response Network, and hospital network. Together with his team, he has integrated dozens of data-driven technologies into clinical operations and is a co-inventor of software to scale machine learning applications. He leads the DIHI Clinical Research & Innovation scholarship, which equips medical students with the business and data science skills required to lead health care innovation efforts. His work has been published in technical venues such as the Machine Learning for Healthcare Proceedings and Fairness, Accountability, and Transparency in Machine Learning Proceedings and clinical journals such as Plos Medicine, Nature Medicine and JAMA Open. He has served as an expert advisor to the American Medical Association, AARP, and National Academies of Medicine on matters related to machine learning, innovation, and policy. He obtained his MD and Masters of Public Policy at Duke University as a Dean's Tuition Scholar and his Bachelor's of Science in Mathematics from UCLA.", 
        "image": "static/images/speakers/m-sendak.jpg", 
        "institution": "Duke Institute for Health Innovation", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954713", 
        "speaker": "Mark Sendak", 
        "title": "Holding a Hammer When There are no Nails - Rapid Iteration to Build COVID-19 Support Programs for Historically Marginalized Communities", 
        "website": "https://dihi.org/team-member/mark-sendak-md/"
      }, 
      {
        "UID": "21K04", 
        "abstract": "Machine learning in healthcare could have transformative impact for patients, caregivers and health systems but the potential benefits remain challenging to realise at scale. Along the path from the development of a model to the realisation of clinical and health-economic impact are a number of challenges and learnings that might be transferable across a range of applications. This talk surveys some recent progress at Google Health and shares learnings from their team in moving from early research to product development; from product development to deployment; and from deployment to early measures of clinical impact.", 
        "bio": "Dr. Alan Karthikesalingam is a surgeon-scientist who leads the healthcare machine learning research group at Google Health in London (and formerly for healthcare at DeepMind).<br /><br />He led DeepMind and Google\u2019s teams in four landmark studies in Nature and Nature Medicine focusing on AI for breast cancer screening with Cancer Research UK, AI for the recognition and prediction of blinding eye diseases with the world\u2019s largest eye hospital (Moorfields) and medical records research with the Veterans Affairs developing AI early warning systems for common causes of patient deterioration, like acute kidney injury.<br /><br />He is leading work on how machine learning approaches can best promote AI safety as the team takes forward its early research into products for clinical care. Alan continues to practice clinically and supervise PhD students as a lecturer in the vascular surgery department of Imperial College, London.", 
        "image": "static/images/speakers/a-karthikesalingam.jpg", 
        "institution": "Google Health - London", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954714", 
        "speaker": " Alan Karthikesalingam", 
        "title": "Lessons on the Path from Code to Clinic  - Some Common Myths in Machine Learning for Healthcare", 
        "website": ""
      }, 
      {
        "UID": "21K05", 
        "abstract": "In medicine, the integration of artificial intelligence (AI) and machine learning (ML) tools could lead to a paradigm shift in which human-AI collaboration becomes integrated in medical decision-making. Despite many years of enthusiasm towards these technologies, the majority of tools fail once they are deployed in the real-world, often due to failures in workflow integration and interface design. In this talk, I will share research using methods in human-computer interaction (HCI) to design and evaluate machine learning tools for real-world clinical use. Results from this work suggest that trends in explainable AI may be inappropriate for clinical environments. I will discuss paths towards designing these tools for real-world medical systems, and describe how we are using collaborations across medicine, data science, and HCI to create machine learning tools for complex medical decisions.", 
        "bio": "Dr. Maia Jacobs is an assistant professor at Northwestern University in Computer Science and Preventive Medicine. Her research contributes to the fields of Computer Science, Human-Computer Interaction (HCI), and Health Informatics through the design and evaluation of novel computing approaches that provide individuals with timely, relevant, and actionable health information. Recent projects include the design and deployment of mobile tools to increase health information access in rural communities, evaluating the influence of AI interface design on expert decision making, and co-designing intelligent decision support tools with clinicians. Her research has been funded by the National Science Foundation, the National Cancer Institute, and the Harvard Data Science Institute and has resulted in the deployment of tools currently being used by healthcare systems and patients around the country. She completed her PhD in Human Centered Computing at Georgia Institute of Technology and was a postdoctoral fellow in the Center for Research on Computation and Society at Harvard University. Jacobs\u2019 work was awarded the iSchools Doctoral Dissertation Award, the Georgia Institute of Technology College of Computing Dissertation Award, and was recognized in the 2016 report to the President of the United States from the President's Cancer Panel, which focused on improving cancer-related outcomes.", 
        "image": "static/images/speakers/m-jacobs.png", 
        "institution": "Northwestern University", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954715", 
        "speaker": "Maia Jacobs", 
        "title": "Bringing AI to the Bedside with User Centered Design", 
        "website": "http://maiajacobs.com/"
      }, 
      {
        "UID": "21K06", 
        "abstract": "The wide adoption of electronic health records (EHR) systems has led to the availability of large clinical datasets available for precision medicine research. EHR data, linked with bio-repository, is a valuable new source for deriving real-word, data-driven prediction models of disease risk and treatment response. Yet, they also bring analytical difficulties. Precise information on clinical outcomes is not readily available and requires labor intensive manual chart review. Synthesizing information across healthcare systems is also challenging due to heterogeneity and privacy. In this talk, I\u2019ll discuss analytical approaches for mining EHR data with a focus on denoising, scalability and transportability . These methods will be illustrated using EHR data from multiple healthcare centers.", 
        "bio": "Dr. Tianxi Cai is the John Rock Professor of Population and Translational Data Science jointly appointed in the Department of Biostatistics at the Harvard T.H. Chan School of Public Health (HSPH) and the Department of Biomedical Informatics (DBMI), Harvard Medical School, where she directs the Translational Data Science Center for a learning healthcare system. Her recent research has been focusing on developing interpretable and robust statistical and machine learning methods for deriving precision medicine strategies and more broadly for mining large-scale biomedical data including electronic health records data.", 
        "image": "static/images/speakers/t-cai.jpg", 
        "institution": "Harvard Medical School", 
        "slideslive_active_date": "2021-04-14T23:59:00.00", 
        "slideslive_id": "38954716", 
        "speaker": "Tianxi Cai", 
        "title": "Precision Medicine with Imprecise EHR Data", 
        "website": "https://celehs.hms.harvard.edu/tcai/"
      }
    ], 
    "tutorials": [
      {
        "UID": "21T01", 
        "abstract": "Causal inference is an important topic in healthcare because a causal relationship between an exposure and a health outcome may suggest an intervention to improve the health outcome. In this tutorial, we provide an introduction to the field of causal inference. We will cover several fundamental topics in causal inference, including the potential outcome framework, structural equation modeling,  propensity score modeling, and instrumental variable analysis. Methods will be illustrated using real clinical examples.", 
        "authors": "Linbo Wang", 
        "bio": "\n    Linbo Wang is an assistant professor in the Department of Statistical Sciences, University of Toronto. He is also an Affiliate Assistant Professor in the Department of Statistics, University of Washington, and a faculty affiliate at Vector Institute. His research interest is centered around causality and its interaction with statistics and machine learning. Prior to these roles, he was a postdoc at Harvard T.H. Chan School of Public Health. He obtained his Ph.D. from the University of Washington.", 
        "rocketchat_id": "", 
        "slideslive_active_date": "2021-03-28T23:59:00.00", 
        "slideslive_id": "38954717", 
        "title": "Causal Inference in Clinical Research: From Theory to Practice"
      }, 
      {
        "UID": "21T02", 
        "abstract": "Mobile health (mHealth) technologies are providing new promising ways to deliver interventions in both clinical and non-clinical settings. Wearable sensors and smartphones collect real-time data streams that provide information about an individual\u2019s current health including both internal (e.g., mood, blood sugar level) and external (e.g., social, location) contexts. Both wearables and smartphones can be used to deliver interventions. mHealth interventions are in current use across a vast number of health-related fields including medication adherence, physical activity, weight loss, mental illness and addictions. This tutorial discusses the micro-randomized trial (MRT), an experimental trial design for use in optimizing real time delivery of sequences of treatment, with an emphasis on mHealth. We introduce the MRT design using HeartSteps, a physical activity study, as an example. We define the causal excursion effect and discuss reasons why this effect is often considered the primary causal effect of interest in MRT analysis. We introduce statistical methods for primary and secondary analyses for MRT with continuous binary outcomes. We discuss the sample size considerations for designing MRTs.", 
        "authors": "Tianchen Qian", 
        "bio": "\n    Tianchen Qian is an Assistant Professor in the Department of Statistics at University of California, Irvine. He completed his PhD at the Johns Hopkins University and was a postdoctoral fellow at Harvard University. His research is focused on the experimental design and statistical analysis methods for developing mobile health interventions. In particular, he has developed causal inference methods for analyzing micro-randomized trial data and sample size calculation approaches for designing micro-randomized trials.\n    <br /><br />Tianchen Qian, Ph.D., Assistant Professor, Department of Statistics, Donald Bren School of Information and Computer Sciences, UC Irvine | Email: <a href='mailto:t.qian@uci.edu'>t.qian@uci.edu</a> | Website: <a href='https://sites.google.com/view/tianchen-qian' target='_blank' rel='noopener'>https://sites.google.com/view/tianchen-qian</a>", 
        "rocketchat_id": "", 
        "slideslive_active_date": "2021-03-28T23:59:00.00", 
        "slideslive_id": "38954718", 
        "title": "Experimental Design and Causal Inference Methods For Micro-Randomized Trials: A Framework for Developing Mobile Health Interventions"
      }, 
      {
        "UID": "21T03", 
        "abstract": "Offline reinforcement learning (offline RL), a.k.a. batch-mode reinforcement learning, involves learning a policy from potentially suboptimal data. In contrast to imitation learning, offline RL does not rely on expert demonstrations, but rather seeks to surpass the average performance of the agents that generated the data. Methodologies such as the gathering of new experience fall short in offline settings, requiring reassessment of fundamental learning paradigms. In this tutorial I aim to provide the necessary background and challenges of this exciting area of research, from off policy evaluation through bandits to deep reinforcement learning.", 
        "authors": "Guy Tennenholtz", 
        "bio": "\n    Guy Tennenholtz is a fourth-year Ph.D. student at the Technion University, advised by Prof. Shie Mannor. His research interests lie in the field of reinforcement learning, and specifically, how offline data can be leveraged to build better agents. Problems of large action spaces, partial observability, confounding bias, and uncertainty are only some of the problems he is actively researching. In his spare time Guy also enjoys creating mobile games, with the vision of incorporating AI into both the game development process and gameplay.", 
        "rocketchat_id": "", 
        "slideslive_active_date": "2021-03-28T23:59:00.00", 
        "slideslive_id": "38954719", 
        "title": "Offline Reinforcement Learning"
      }, 
      {
        "UID": "21T04", 
        "abstract": "As machine learning black boxes are increasingly being deployed in domains such as healthcare and criminal justice, there is growing emphasis on building tools and techniques for explaining these black boxes in a post hoc manner. Such explanations are being leveraged by domain experts to diagnose systematic errors and underlying biases of black boxes. However, recent research has shed light on the vulnerabilities of popular post hoc explanation techniques. In this tutorial, I will provide a brief overview of post hoc explanation methods with special emphasis on feature attribution methods such as LIME and SHAP. I will then discuss recent research which demonstrates that these methods are brittle, unstable, and are vulnerable to a variety of adversarial attacks. Lastly, I will present two solutions to address some of the vulnerabilities of these methods \u2013 (i)  a generic framework based on adversarial training that is designed to make post hoc explanations more stable and robust to shifts in the underlying data, and (ii) a Bayesian framework that captures the uncertainty associated with post hoc explanations and in turn allows us to generate reliable explanations which satisfy user specified levels of confidence. Overall, this tutorial will provide a bird\u2019s eye view of the state-of-the-art in the burgeoning field of explainable machine learning.", 
        "authors": "Hima Lakkaraju", 
        "bio": "\n    Hima Lakkaraju is an Assistant Professor at Harvard University focusing on explainability, fairness, and robustness of machine learning models. She has also been working with various domain experts in criminal justice and healthcare to understand the real world implications of explainable and fair ML. Hima has recently been named one of the 35 innovators under 35 by MIT Tech Review, and has received best paper awards at SIAM International Conference on Data Mining (SDM) and INFORMS. She has given invited workshop talks at ICML, NeurIPS, AAAI, and CVPR, and her research has also been covered by various popular media outlets including the New York Times, MIT Tech Review, TIME, and Forbes. For more information, please visit: <a href='https://himalakkaraju.github.io' target='_blank' rel='noopener'>https://himalakkaraju.github.io</a>", 
        "rocketchat_id": "", 
        "slideslive_active_date": "2021-03-28T23:59:00.00", 
        "slideslive_id": "38954720", 
        "title": "Explainable ML: Understanding the Limits and Pushing the Boundaries"
      }, 
      {
        "UID": "21T05", 
        "abstract": "Phenotyping is the process of identifying a patient\u2019s health state based on the information in their electronic health records. In this tutorial, we will discuss why phenotyping is a challenging problem from both a practical and methodological perspective. We will focus primarily on the the challenges in obtaining annotated phenotype information from patient records and present statistical learning methods that leverage unlabeled examples to improve model estimation and evaluation to reduce the annotation burden.", 
        "authors": "Jesse Gronsbell | Chuan Hong | Molei Liu | Clara-Lea Bonzel | Aaron Sonabend", 
        "bio": "\n    Jesse Gronsbell is an Assistant Professor in the Department of Statistical Sciences at the University of Toronto.  Prior to joining U of T,  Jesse spent a couple of years as a data scientist in the Mental Health Research and Development Group at Alphabet's Verily Life Sciences.  Her primary interest is in the development of statistical methods for modern digital data sources such as electronic health records and mobile health data.\n    <br /><br />Chuan Hong is an instructor in biomedical informatics from the Department of Biomedical Informatics (DBMI) at Harvard Medical School. She received her PhD in Biostatistics from the University of Texas Health Science Center at Houston. Her doctoral research focused on meta-analysis and DNA methylation detection. At DBMI, Chuan's research interests lie in developing statistical and computational methods for biomarker evaluation, predictive modeling, and precision medicine with biomedical data. In particular, she is interested in combining electronic medical records with biorepositories and relevant resources to improve phenotyping accuracy, detect novel biomarkers, and monitor disease progression in clinical research.\n    <br /><br />Molei Liu is a 4th year PhD candidate in the Biostatistics department at Harvard T.H. Chan School of Public Health. He received a Bachelor's degree in Statistics from Peking University. Molei has been working in areas including high dimensional statistics, distributed learning, semi-supervised learning, semi-parametric inference, and model-X inference. He has also been working on methods for phenome-wide association studies (PheWAS) using electronic health records data.\n    <br /><br />Clara-Lea Bonzel is a research assistant at the Department of Biomedical Informatics at Harvard Medical School. She is mainly interested in personalized medicine using phenomic and genomic data, and model selection and evaluation.   Clara-Lea received her master's degree in Applied Mathematics and Financial Engineering from the Swiss Federal Institute of Technology (EPFL).\n    <br /><br />Aaron Sonabend is a PhD candidate in the Biostatistics department at Harvard T.H. Chan School of Public Health. He is primarily focused on developing robust reinforcement learning and natural language processing methods for contexts with sampling bias, partially observed rewards, or strong distribution shifts. He is interested in healthcare and biomedical applications, such as finding optimal sequential treatment regimes for complex diseases, and phenotyping using electronic health records. Aaron holds a Bachelor's degree in Applied Mathematics, and in Economics from the National Autonomous Technological Institute of Mexico (ITAM).", 
        "rocketchat_id": "", 
        "slideslive_active_date": "2021-03-28T23:59:00.00", 
        "slideslive_id": "38954721", 
        "title": "Semi-supervised Phenotyping with Electronic Health Records"
      }
    ], 
    "workshops": [
      {
        "UID": "21WS01", 
        "abstract": "In many real-world environments, the details of decision-making processes are not fully known, e.g., how oncologists decide on specific radiation therapy treatment plans for cancer patients, how clinicians decide on medication dosages for different patients, or how hypertension patients choose their diet to control their illness. While conventional machine learning and statistical methods can be used to better understand such processes, they often fail to provide meaningful insights into the unknown parameters when the problem's setting is heavily constrained. Similarly, conventional constrained inference models, such as inverse optimization, are not well equipped for data-driven problems. In this study, we develop a novel methodology (called MLIO) that combines machine learning and inverse optimization techniques to recover the utility functions of a black-box decision-making process. Our method can be applied to settings where different types of data are required to capture the problem. MLIO is specifically developed with data-intensive medical decision-making environments in mind. We evaluate our approach in the context of personalized diet recommendations for patients, building on a large dataset of historical daily food intakes of patients from NHANES. MLIO considers these prior dietary behaviors in addition to complementary data (e.g., demographics and preexisting conditions) to recover the underlying criteria that the patients had in mind when deciding on their food choices. Once the underlying criteria are known, an optimization model can be used to find personalized diet recommendations that adhere to patients' behavior while meeting all required dietary constraints.", 
        "authors": "Farzin Ahmadi, Tinglong Dai, and Kimia Ghobadi (Johns Hopkins University)", 
        "title": "Emulating Human Decision-Making Under Multiple Constraints"
      }, 
      {
        "UID": "21WS02", 
        "abstract": "Deep neural networks have increasingly been used as an auxiliary tool in healthcare applications, due to their ability to improve performance of several diagnosis tasks. However, these methods are not widely adopted in clinical settings due to the practical limitations in the reliability, generalizability, and interpretability of deep learning based systems. As a result, methods have been developed that impose additional constraints during network training to gain more control as well as improve interpretabilty, facilitating their acceptance in healthcare community. In this work, we investigate the benefit of using Orthogonal Spheres (OS) constraint for classification of COVID-19 cases from chest X-ray images. The OS constraint can be written as a simple orthonormality term which is used in conjunction with the standard cross-entropy loss during classification network training. Previous studies have demonstrated significant benefits in applying such constraints to deep learning models. Our findings corroborate these observations, indicating that the orthonormality loss function effectively produces improved semantic localization via GradCAM visualizations, enhanced classification performance, and reduced model calibration error. Our approach achieves an improvement in accuracy of 1.6% and 4.8% for two- and three-class classification, respectively; similar results are found for models with data augmentation applied. In addition to these findings, our work also presents a new application of the OS regularizer in healthcare, increasing the post-hoc interpretability and performance of deep learning models for COVID-19 classification to facilitate adoption of these methods in clinical settings. We also identify the limitations of our strategy that can be explored for further research in future.", 
        "authors": "Ella Y. Wang (BASIS Chandler); Anirudh Som (SRI International); Ankita Shukla, Hongjun Choi, and Pavan Turaga (ASU)", 
        "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint"
      }, 
      {
        "UID": "21WS03", 
        "abstract": "Meta-analysis is a systematic approach for understanding a phenomenon by analyzing the results of many previously published experimental studies related to the same treatment and outcome measurement. It is an important tool for medical researchers and clinicians to derive reliable conclusions regarding the overall effect of treatments and interventions (e.g., drugs) on a certain outcome (e.g., the severity of a disease). Unfortunately, conventional meta-analysis involves great human effort, i.e., it is constructed by hand and is extremely time-consuming and labor-intensive, rendering a process that is inefficient in practice and vulnerable to human bias. To overcome these challenges, we work toward automating meta-analysis with a focus on controlling for the potential biases. Automating meta-analysis consists of two major steps: (1) extracting information from scientific publications written in natural language, which is different and noisier than what humans typically extract when conducting a meta-analysis; and (2) modeling meta-analysis, from a novel \\textit{causal-inference} perspective, to control for the potential biases and summarize the treatment effect from the outputs of the first step. Since sufficient prior work exists for the first step, this study focuses on the second step. The core contribution of this work is a multiple causal inference algorithm tailored to the potentially noisy and biased information automatically extracted by current natural language processing systems. Empirical evaluations on both synthetic and semi-synthetic data show that the proposed approach for automated meta-analysis yields high-quality performance.", 
        "authors": "Lu Cheng (Arizona State University); Dmitriy Katz-Rogozhnikov, Kush R. Varshney, and Ioana Baldini (IBM Research)", 
        "title": "Automated Meta-Analysis in Medical Research: A Causal Learning Perspective"
      }, 
      {
        "UID": "21WS04", 
        "abstract": "Attention is a powerful concept in computer vision. End-to-end networks that learn to focus selectively on regions of an image or video often perform strongly. However, other image regions, while not necessarily containing the signal of interest, may contain useful context. We present an approach that exploits the idea that statistics of noise may be shared between the regions that contain the signal of interest and those that do not. Our technique uses the inverse of an attention mask to generate a noise estimate that is then used to denoise temporal observations. We apply this to the task of camera-based physiological measurement. A convolutional attention network is used to learn which regions of a video contain the physiological signal and generate a preliminary estimate. A noise estimate is obtained by using the pixel intensities in the inverse regions of the learned attention mask, this in turn is used to refine the estimate of the physiological signal. We perform experiments on two large benchmark datasets and show that this approach produces state-of-the-art results, increasing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation error by as much as 30%, recovering subtle waveform dynamics, and generalizing from RGB to NIR videos without retraining.", 
        "authors": "Ewa Nowara (RICE UNIVERSITY); Daniel McDuff (Microsoft Research); Ashok Veeraraghavan (RICE UNIVERSITY)", 
        "title": "The Benefit of Distraction: Denoising Remote Vitals Measurements using Inverse Attention"
      }, 
      {
        "UID": "21WS05", 
        "abstract": "Electronic health records (EHRs) provide an abundance of data for clinical outcomes modeling. The prevalence of EHR data has enabled a number of studies using a variety of machine learning algorithms to predict potential adverse events. However, these studies do not account for the heterogeneity present in EHR data, including various lengths of stay, various frequencies of vitals captured in invasive versus non-invasive fashion, and various repetitions (or lack of thereof) of laboratory examinations. Therefore, studies limit the types of features extracted or the domain considered to provide a more homogeneous training set to machine learning models. The heterogeneity in this data represents important risk differences in each patient. In this work, we examine such data in an intensive care unit (ICU) setting, where the length of stay and the frequency of data gathered may vary significantly based upon the severity of patient condition. Therefore, it is unreasonable to use the same model for patients first entering the ICU versus those that have been there for above average lengths of stay. Developing multiple individual models to account for different patient cohorts, different lengths of stay, and different sources for key vital sign data may be tedious and not account for rare cases well. We address this challenge by developing a dynamic model, based upon meta-learning, to adapt to data heterogeneity and generate predictions of various outcomes across the different lengths of data. We compare this technique against a set of benchmarks on a publicly-available ICU dataset (MIMIC-III) and demonstrate improved model performance by accounting for data heterogeneity.", 
        "authors": "Lida Zhang (Texas A&M University); Xiaohan Chen, Tianlong Chen, and Zhangyang Wang (University of Texas at Austin); Bobak J. Mortazavi (Texas A&M University)", 
        "title": "DynEHR: Dynamic Adaptation of Models with Data Heterogeneity in Electronic Health Records"
      }, 
      {
        "UID": "21WS06", 
        "abstract": "Machine Learning (ML) is widely used to automatically extract meaningful information from Electronic Health Records (EHR) to support operational, clinical, and financial decision making. However, ML models require a large number of annotated examples to provide satisfactory results, which is not possible in most healthcare scenarios due to the high cost of clinician labeled data. Active Learning (AL) is a process of selecting the most informative instances to be labeled by an expert to further train a supervised algorithm. We demonstrate the effectiveness of AL in multi-label text classification in the clinical domain. In this context, we apply a set of well-known AL methods to help automatically assign ICD-9 codes on the MIMIC-III dataset. Our results show that the selection of informative instances provides satisfactory classification with a significantly reduced training set (8.3\\% of the total instances). We conclude that AL methods can significantly reduce the manual annotation cost while preserving model performance.", 
        "authors": "Martha Ferreira (Dalhousie University); Michal Malyska and Nicola Sahar (Semantic Health); Riccardo Miotto (Icahn School of Medicine at Mount Sinai); Fernando Paulovich (Dalhousie University); Evangelos Milios (Dalhousie University, Faculty of Computer Scienc)", 
        "title": "Active Learning for Medical Code Assignment"
      }, 
      {
        "UID": "21WS07", 
        "abstract": "Assessment of COVID-19 pandemic predictions indicates that differential equation-based epidemic spreading models are less than satisfactory in the contemporary world of intense human connectivity. Network-based simulations are more apt for studying the contagion dynamics due to their ability to model heterogeneity of human interactions. However, the quality of predictions in network-based models depends on how well the underlying wire-frame approximates the real social contact network of the population. In this paper, we propose a framework to create a modular wire-frame to mimic the social contact network of geography by lacing it with demographic information. The proposed inter-connected network sports small-world topology, accommodates density variations in the geography, and emulates human interactions in family, social, and work spaces. The resulting wire-frame is a generic and potent instrument for urban planners, demographers, economists, and social scientists to simulate different \"what-if\" scenarios and predict epidemic variables. The basic frame can be laden with any economic, social, urban data that can potentially shape human connectance. We present a preliminary study of the impact of variations in contact patterns due to density and demography on the epidemic variables.", 
        "authors": "Kirti Jain (Department of Computer Science, University of Delhi, Delhi, India); Sharanjit Kaur (Acharya Narendra Dev College, University of Delhi, Delhi, India); Vasudha Bhatnagar (Department of Computer Science, University of Delhi, Delhi, India)", 
        "title": "Framing Social Contact Networks for Contagion Dynamics"
      }, 
      {
        "UID": "21WS08", 
        "abstract": "Shaping an epidemic with an adaptive contact restriction policy that balances the disease and socioeconomic impact has been the holy grail during the COVID-19 pandemic. Most of the existing work on epidemiological models focuses on scenario-based forecasting via simulation but techniques for explicit control of epidemics via an analytical framework are largely missing. In this paper, we consider the problem of determining the optimal control policy for transmission rate assuming SIR dynamics, which is the most widely used epidemiological paradigm. We first demonstrate that the SIR model with infectious patients and susceptible contacts (i.e., product of transmission rate and susceptible population) interpreted as predators and prey respectively reduces to a Lotka-Volterra (LV) predator-prey model. The modified SIR system (LVSIR) has a stable equilibrium point, an 'energy' conservation property, and exhibits bounded cyclic behaviour similar to an LV system. This mapping permits a theoretical analysis of the control problem supporting some of the recent simulation-based studies that point to the benefits of periodic interventions. We use a control-Lyapunov approach to design adaptive control policies (CoSIR) to nudge the SIR model to the desired equilibrium that permits ready extensions to richer compartmental models. We also describe a practical implementation of this transmission control method by approximating the ideal control with a finite, but a time-varying set of restriction levels. We provide experimental results comparing with periodic lockdowns on few different geographical regions (India, Mexico, Netherlands) to demonstrate the efficacy of this approach.", 
        "authors": "Harsh Maheshwari and Shreyas Shetty (Flipkart Internet Private Ltd.); Nayana Bannur (Wadhwani AI); Srujana Merugu (Independent)", 
        "title": "CoSIR: Managing an Epidemic via Optimal Adaptive Control of Transmission Rate Policy"
      }, 
      {
        "UID": "21WS09", 
        "abstract": "A major obstacle to the integration of deep learning models for chest x-ray interpretation into clinical settings is the lack of understanding of their failure modes. In this work, we first investigate whether there are clinical subgroups that chest x-ray models are likely to misclassify. We find that older patients and patients with a lung lesion or pneumothorax finding have a higher probability of being misclassified on some diseases. Second, we develop misclassification predictors on chest x-ray models using their outputs and clinical features. We find that our best performing misclassification identifier achieves an AUROC close to 0.9 for most diseases. Third, employing our misclassification identifiers, we develop a corrective algorithm to selectively flip model predictions that have high likelihood of misclassification at inference time. We observe F1 improvement on the prediction of Consolidation (0.008, 95%CI[0.005, 0.010]) and Edema (0.003, 95%CI[0.001, 0.006]). By carrying out our investigation on ten distinct and high-performing chest x-ray models, we are able to derive insights across model architectures and offer a generalizable framework applicable to other medical imaging tasks.", 
        "authors": "Emma Chen, Andy Kim, Rayan Krishnan, Andrew Y. Ng, and Pranav Rajpurkar (Stanford University)", 
        "title": "CheXbreak: Misclassification Identification for Deep Learning Models Interpreting Chest X-rays"
      }, 
      {
        "UID": "21WS10", 
        "abstract": "Contrastive learning is a form of self-supervision that can leverage unlabeled data to produce pretrained models. While contrastive learning has demonstrated promising results on natural image classification tasks, its application to medical imaging tasks like chest X-ray interpretation has been limited. In this work, we propose MoCo-CXR, which is an adaptation of the contrastive learning method Momentum Contrast (MoCo), to produce models with better representations and initializations for the detection of pathologies in chest X-rays. In detecting pleural effusion, we find that linear models trained on MoCo-CXR-pretrained representations outperform those without MoCo-CXR-pretrained representations, indicating that MoCo-CXR-pretrained representations are of higher-quality. End-to-end fine-tuning experiments reveal that a model initialized via MoCo-CXR-pretraining outperforms its non-MoCo-CXR-pretrained counterpart. We find that MoCo-CXR-pretraining provides the most benefit with limited labeled training data. Finally, we demonstrate similar results on a target Tuberculosis dataset unseen during pretraining, indicating that MoCo-CXR-pretraining endows models with representations and transferability that can be applied across chest X-ray datasets and tasks.", 
        "authors": "Hari Sowrirajan, Jingbo Yang, Andrew Ng, and Pranav Rajpurkar (Stanford University)", 
        "title": "MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models"
      }, 
      {
        "UID": "21WS11", 
        "abstract": "Inertial Measurement Unit (IMU) sensors are becoming increasingly ubiquitous in everyday devices such as smartphones, fitness watches, etc. As a result, the array of health-related applications that tap onto this data has been growing, as well as the importance of designing accurate prediction models for tasks such as human activity recognition (HAR). However, one important task that has received little attention is the prediction of an individual's heart rate when undergoing a physical activity using IMU data. This could be used, for example, to determine which activities are safe for a person without having him/her actually perform them. We propose a neural architecture for this task composed of convolutional and LSTM layers, similarly to the state-of-the-art techniques for the closely related task of HAR. However, our model includes a convolutional network that extracts, based on sensor data from a previously executed activity, a physical conditioning embedding (PCE) of the individual to be used as the LSTM's initial hidden state. We evaluate the proposed model, dubbed PCE-LSTM, when predicting the heart rate of 23 subjects performing a variety of physical activities from IMU-sensor data available in public datasets (PAMAP2, PPG-DaLiA). For comparison, we use as baselines the only model specifically proposed for this task, and an adapted state-of-the-art model for HAR. PCE-LSTM yields over 10% lower mean absolute error. We demonstrate empirically that this error reduction is in part due to the use of the PCE. Last, we use the two datasets (PPG-DaLiA, WESAD) to show that PCE-LSTM can also be successfully applied when photoplethysmography (PPG) sensors are available to rectify heart rate measurement errors caused by movement, outperforming the state-of-the-art deep learning baselines by more than 30%.", 
        "authors": "Davi Pedrosa de Aguiar, Ot\u00e1vio Augusto Silva, and Fabricio Murai (Universidade Federal de Minas Gerais)", 
        "title": "Encoding physical conditioning from inertial sensors for multi-step heart rate estimation"
      }, 
      {
        "UID": "21WS12", 
        "abstract": "COVID-19 pandemic has been ravaging the world we know since it's insurgence. Computer-Aided Diagnosis (CAD) systems with high precision and reliability can play a vital role in the battle against COVID-19. Most of the existing works in the literature focus on developing sophisticated methods yielding high detection performance yet not addressing the issue of predictive uncertainty. Uncertainty estimation has been explored heavily in the literature for Deep Neural Networks; however, not much work focused on this issue on COVID-19 detection. In this work, we explore the efficacy of state-of-the-art (SOTA) uncertainty estimation methods on COVID-19 detection. We propose to augment the best performing method by using feature denoising algorithm to gain higher Positive Predictive Value (PPV) on COVID positive cases. Through extensive experimentation, we identify the most lightweight and easy-to-deploy uncertainty estimation framework that can effectively identify the confusing COVID-19 cases for expert analysis while performing comparatively with the existing resource heavy uncertainty estimation methods. In collaboration with medical professionals, we further validate the results to ensure the viability of the framework in clinical practice.", 
        "authors": "Krishanu Sarker (Georgia State University); Sharbani Pandit (Georgia Institute of Technology); Anupam Sarker (Institute of Epidemiology, Disease Control and Research); Saeid Belkasim and Shihao Ji (Georgia State University)", 
        "title": "Towards Reliable and Trustworthy Computer-Aided Diagnosis Predictions: Diagnosing COVID-19 from X-Ray Images"
      }, 
      {
        "UID": "21WS13", 
        "abstract": "We systematically evaluate the performance of deep learning models in the presence of diseases not labeled for or present during training. First, we evaluate whether deep learning models trained on a subset of diseases (seen diseases) can detect the presence of any one of a larger set of diseases. We find that models tend to falsely classify diseases outside of the subset (unseen diseases) as \"no disease\". Second, we evaluate whether models trained on seen diseases can detect seen diseases when co-occurring with diseases outside the subset (unseen diseases). We find that models are still able to detect seen diseases even when co-occurring with unseen diseases. Third, we evaluate whether feature representations learned by models may be used to detect the presence of unseen diseases given a small labeled set of unseen diseases. We find that the penultimate layer provides useful features for unseen disease detection. Our results can inform the safe clinical deployment of deep learning models trained on a non-exhaustive set of disease classes.", 
        "authors": "Siyu Shi (Department of Medicine, School of Medicine, Stanford University); Ishaan Malhi, Kevin Tran, Andrew Y. Ng, and Pranav Rajpurkar (Department of Computer Science, Stanford University)", 
        "title": "CheXseen: Unseen Disease Detection for Deep Learning Interpretation of Chest X-rays"
      }, 
      {
        "UID": "21WS14", 
        "abstract": "We explore the application of graph neural networks (GNNs) to the problem of estimating exposure to an infectious pathogen and probability of transmission. Specifically, given a datatset in which a subset of patients are known to be infected and information in the form of a graph about who has interacted with whom, we aim to directly estimate transmission dynamics, i.e., what types of interactions (e.g., length and number) lead to transmission events. While, graph neural networks (GNNs) have proven capable of learning meaningful representations from graph data, they commonly assume tasks with high homophily (i.e., nodes that share an edge look similar). Recently researchers have proposed techniques for addressing problems with low homophily (e.g., adding residual connections to GNNs). In our problem setting, homophily is high on average, the majority of patients do not become infected. But, homophily remains low with respect to the minority class. In this paper, we characterize this setting as particularly challenging for GNNs. Given the asymmetry in homophily between classes, we hypothesize that solutions designed to address low homophily on average will not suffice and instead propose a solution based on attention. Applied to both real-world and synthetic network data, we test this hypothesis and explore the ability of GNNs to learn complex transmission dynamics directly from network data. Overall, attention proves to be an effective mechanism for addressing low homophily in the minority class (AUROC with 95\\% CI: GCN 0.684 (0.659,0.710) vs. GAT 0.715 (0.688,0.742)) and such a data-driven approach can outperform approaches based on potentially flawed expert knowledge.", 
        "authors": "Jeeheh Oh (University of Michigan, Ann Arbor); Jenna Wiens (University of Michigan)", 
        "title": "A Data-Driven Approach to Estimating Infectious Disease Transmission from Graphs: A Case of Class Imbalance Driven Low Homophily"
      }, 
      {
        "UID": "21WS15", 
        "abstract": "Explainable artificial intelligence provides an opportunity to improve prediction accuracy over standard linear models using 'black box' machine learning (ML) models while still revealing insights into a complex outcome such as all-cause mortality. We propose the IMPACT (Interpretable Machine learning Prediction of All-Cause morTality) framework that implements and explains complex, non-linear ML models in epidemiological research, by combining a tree ensemble mortality prediction model and an explainability method. We use 133 variables from NHANES 1999-2014 datasets (number of samples: ?? = 47, 261) to predict all-cause mortality. To explain our model, we extract local (i.e., per-sample) explanations to verify well-studied mortality risk factors, and make new dis- coveries. We present major factors for predicting ??-year mortality (?? = 1, 3, 5) across different age groups and their individualized im- pact on mortality prediction. Moreover, we highlight interactions between risk factors associated with mortality prediction, which leads to findings that linear models do not reveal. We demonstrate that compared with traditional linear models, tree-based models have unique strengths such as: (1) improving prediction power, (2) making no distribution assumptions, (3) capturing non-linear relationships and important thresholds, (4) identifying feature interactions, and (5) detecting different non-linear relationships between models. Given the popularity of complex ML models in prognostic research, combining these models with explainability methods has implications for further applications of ML in medical fields. To our knowledge, this is the first study that combines complex ML models and state-of-the-art feature attributions to explain mortality prediction, which enables us to achieve higher prediction accuracy and gain new insights into the effect of risk factors on mortality.", 
        "authors": "Wei Qiu, Hugh Chen, Ayse Berceste Dincer, and Su-In Lee (Paul G. Allen School of Computer Science and Engineering, University of Washington)", 
        "title": "Interpretable Machine Learning Prediction of All-cause Mortality"
      }, 
      {
        "UID": "21WS16", 
        "abstract": "Cardiogenic shock is a deadly and complicated illness. Despite extensive research into treating cardiogenic shock, mortality remains high and has not decreased over time. Patients suffering from cardiogenic shock are highly heterogeneous, and developing an understanding of phenotypes among these patients is crucial for understanding this disease and the appropriate treatments for individual patients. In this work, we develop a deep mixture of experts approach to jointly find phenotypes among patients with cardiogenic shock while simultaneously estimating their risk of in-hospital mortality. Although trained with information regarding treatment and outcomes, after training, the proposed model is decomposable into a network that clusters patients into phenotypes from information available prior to treatment. This model is validated on a synthetic dataset and then applied to a cohort of 28,304 patients with cardiogenic shock. The full model predicts in-hospital mortality on this cohort with an AUROC of 0.85 \u00b1 0.01. The model discovers five phenotypes among the population, finding statistically different mortality rates among them and among treatment choices within those groups. This approach allows for grouping patients in clinical clusters with different rates of device utilization and different risk of mortality. This approach is suitable for jointly finding phenotypes within a clinical population and in modeling risk among that population.", 
        "authors": "Nathan C. Hurley (Texas A&M University); Alyssa Berkowitz (Yale University); Frederick Masoudi (University of Colorado School of Medicine); Joseph Ross and Nihar Desai (Yale University); Nilay Shah (Mayo Clinic); Sanket Dhruva (UCSF School of Medicine); Bobak J. Mortazavi (Texas A&M University)", 
        "title": "Outcomes-Driven Clinical Phenotyping in Patients with Cardiogenic Shock for Risk Modeling and Comparative Treatment Effectiveness"
      }, 
      {
        "UID": "21WS17", 
        "abstract": "Severe infectious diseases such as the novel coronavirus (COVID-19) pose a huge threat to public health. Stringent control measures, such as school closures and stay-at-home orders, while having significant effects, also bring huge economic losses. In the face of an emerging infectious disease, a crucial question for policymakers is how to make the trade-off and implement the appropriate interventions timely, with the existence of huge uncertainty. In this work, we propose a Multi-Objective Model-based Reinforcement Learning framework to facilitate data-driven decision making and minimize the long-term overall cost. Specifically, at each decision point, a Bayesian epidemiological model is first learned as the environment model, and then the proposed model-based multi-objective planning algorithm is applied to find a set of Pareto-optimal policies. This framework, combined with the prediction bands for each policy, provides a real-time decision support tool for policymakers. The application is demonstrated with the spread of COVID-19 in China.", 
        "authors": "Runzhe Wan, Xinyu Zhang, and Rui Song (North Carolina State University)", 
        "title": "Multi-Objective Model-based Reinforcement Learning for Infectious Disease Control"
      }, 
      {
        "UID": "21WS18", 
        "abstract": "With the growing amount of text in health data, there have beenrapid advances in large pre-trained models that can be applied to awide variety of biomedical tasks with minimal task-specific mod-ifications. Emphasizing the cost of these models, which renderstechnical replication challenging, this paper summarizes experi-ments conducted in replicating BioBERT and further pre-trainingand careful fine-tuning in the biomedical domain. We also inves-tigate the effectiveness of domain-specific and domain-agnosticpre-trained models across downstream biomedical NLP tasks. Ourfinding confirms that pre-trained models can be impactful in somedownstream NLP tasks (QA and NER) in the biomedical domain;however, this improvement may not justify the high cost of domain-specific pre-training.", 
        "authors": "Paul Grouchi (Untether AI); Shobhit Jain (Manulife); Michael Liu (Tealbook); Kuhan Wang (CIBC); Max Tian (Adeptmind); Nidhi Arora (Intact); Hillary Ngai (University of Toronto); Faiza Khan Khattak (Manulife); Elham Dolatabadi and Sedef Akinli Kocak (Vector Institute)", 
        "title": "An Experimental Evaluation of Transformer-based LanguageModels in the Biomedical Domain"
      }, 
      {
        "UID": "21WS19", 
        "abstract": "Question Answering (QA) is a widely-used framework for developing and evaluating an intelligent machine. In this light, QA on Electronic Health Records (EHR), namely EHR QA, can work as a crucial milestone towards developing an intelligent agent in healthcare. EHR data are typically stored in a  relational database, which can also be converted to a directed acyclic graph, allowing two approaches for EHR QA: Table-based QA and Knowledge Graph-based QA. We hypothesize that the graph-based approach is more suitable for EHR QA as graphs can represent relations between entities and values more naturally compared to tables, which essentially require JOIN operations. In this paper, we propose a graph-based EHR QA where natural language queries are converted to SPARQL instead of SQL. To validate our hypothesis, we create four EHR QA datasets (graph-based VS table-based, and simplified database schema VS original database schema), based on a table-based dataset MIMICSQL. We test both a simple Seq2Seq model and a state-of-the-art EHR QA model on all datasets where the graph-based datasets facilitated up to 34% higher accuracy than the table-based dataset without any modification to the model architectures. Finally, all datasets will be open-sourced to encourage further EHR QA research in both directions.", 
        "authors": "Junwoo Park and Youngwoo Cho (Korea Advanced Institute of Science and Technology (KAIST)); Haneol Lee (Yonsei University); Jaegul Choo and Edward Choi (Korea Advanced Institute of Science and Technology (KAIST))", 
        "title": "Knowledge Graph-based Question Answering with Electronic Health Records"
      }, 
      {
        "UID": "21WS20", 
        "abstract": "There is an increased adoption of electronic health record (EHR) systems by variety of hospitals and medical centers. This provides an opportunity to leverage automated computer systems in assisting healthcare workers. One of the least utilized but rich source of patient information is the unstructured clinical text. In this work, we develop \\model, a chart-aware temporal attention network for learning patient representations from clinical notes. We introduce a novel representation where each note is considered a single unit, like a sentence, and composed of attention-weighted words. The notes in turn are aggregated into a patient representation using a second weighting unit, note attention. Unlike standard attention computations which focus only on the content of the note, we incorporate the chart-time for each note as a constraint for attention calculation. This allows our model to focus on notes closer to the prediction time. Using the MIMIC-III dataset, we empirically show that our patient representation and attention calculation achieves the best performance in comparison with various state-of-the-art baselines for one-year mortality prediction and 30-day hospital readmission. Moreover, the attention weights can be used to offer transparency into our model's predictions.", 
        "authors": " Zelalem Gero and Joyce Ho (Emory University)", 
        "title": "CATAN: Chart-aware temporal attention network for clinical text classification"
      }, 
      {
        "UID": "21WS21", 
        "abstract": "Survival analysis is a challenging variation of regression modeling because of the presence of censoring, where the outcome measurement is only partially known, due to, for example, loss to follow up. Such problems come up frequently in medical applications, making survival analysis a key endeavor in biostatistics and machine learning for healthcare, with Cox regression models being amongst the most commonly employed models. We describe a new approach for survival analysis regression models, based on learning mixtures of Cox regressions to model individual survival distributions. We propose an approximation to the Expectation Maximization algorithm for this model that does hard assignments to mixture groups to make optimization efficient. In each group assignment, we fit the hazard ratios within each group using deep neural networks, and the baseline hazard for each mixture component non-parametrically. We perform experiments on multiple real world datasets, and look at the mortality rates of patients across ethnicity and gender. We emphasize the importance of calibration in healthcare settings and demonstrate that our approach outperforms classical and modern survival analysis baselines, both in terms of discriminative performance and calibration, with large gains in performance on the minority demographics.", 
        "authors": "Chirag Nagpal (Carnegie Mellon University); Steve Yadlowsky; Negar Rostamzadeh; and Katherine Heller (Google Brain)", 
        "title": "Deep Cox Mixtures for Survival Regression"
      }
    ]
  }, 
  "has_data": true, 
  "has_summary": {
    "2020": true, 
    "2021": true
  }, 
  "years_list": [
    "2021", 
    "2020"
  ]
}
